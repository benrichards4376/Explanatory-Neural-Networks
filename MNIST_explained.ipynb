{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d45c41-cfae-4cc1-a6fb-d1b1d7b78916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22ac08-6317-4650-83f3-97e3d9c194b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "batch_size = 32\n",
    "# Transform to convert images to PyTorch tensors and normalize them\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data for MNIST\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab08fb7-e1cc-4540-840a-a97b6d16be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_indices = []\n",
    "\n",
    "for i, (images, labels) in enumerate(trainloader):\n",
    "    all_images.extend(images)\n",
    "    all_indices.extend(range(i * len(images), (i + 1) * len(images)))\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "all_images = torch.stack(all_images)\n",
    "all_indices = torch.tensor(all_indices)\n",
    "\n",
    "\n",
    "\n",
    "# Function to display an image given its index\n",
    "def imshow_by_index(index):\n",
    "    img = all_images[index] / 2 + 0.5  # Unnormalize\n",
    "    plt.imshow(img.permute(1, 2, 0))  # Convert from Tensor image\n",
    "    plt.show()\n",
    "\n",
    "# Example: Display the first four images\n",
    "for i in range(4):\n",
    "    imshow_by_index(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5adf74a-f735-4b97-b954-47bdc317f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableNode(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(TrainableNode, self).__init__()\n",
    "        self.linear = nn.Linear(input_features, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        # Define your layers here\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.explainable_node = TrainableNode(128, 1)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x, return_explainable=False):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x1 = torch.relu(self.fc1(x))\n",
    "        if return_explainable:\n",
    "            explainable_output = self.explainable_node(x1).squeeze()\n",
    "        x = torch.relu(self.fc2(x1))\n",
    "        x = self.fc3(x)\n",
    "        if return_explainable:\n",
    "            return x, explainable_output\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    def forward_with_explainable(self, x):\n",
    "        # This method is specifically for when you want to use the explainable node\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        explainable_output = self.explainable_node(x)\n",
    "        return explainable_output\n",
    "        \n",
    "\n",
    "class ExplainableNetwork:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.activations_per_input = {}\n",
    "        self.weights_per_layer = {}\n",
    "        self.gradients_per_input = {} \n",
    "        self.current_epoch = 0\n",
    "        self.num_epochs = 0\n",
    "        self.batch_counter = 0\n",
    "\n",
    "        self.expected_outputs = []\n",
    "        self.predicted_outputs = []\n",
    "        \n",
    "        # Register hooks for each layer\n",
    "        for name, module in model.named_modules():\n",
    "            if name == 'explainable_node':  # Skip the explainable_node by its name\n",
    "                continue\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                self.weights_per_layer[name] = None\n",
    "                module.register_forward_hook(self.create_forward_hook(name))\n",
    "                module.register_full_backward_hook(self.create_backward_hook(name))\n",
    "\n",
    "\n",
    "    def create_forward_hook(self, layer_name):\n",
    "        def forward_hook(module, input, output):\n",
    "            # On the last epoch, store activations for each input\n",
    "            if self.current_epoch == self.num_epochs - 1:\n",
    "                self.store_activations(layer_name, output)\n",
    "            # Always store the current weights\n",
    "            self.weights_per_layer[layer_name] = module.weight.data.clone()\n",
    "        return forward_hook\n",
    "\n",
    "    def create_backward_hook(self, layer_name):\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            # Only store gradients on the last epoch\n",
    "            if self.current_epoch == self.num_epochs - 1:\n",
    "                # grad_output[0] contains the gradient with respect to the output of the layer\n",
    "                self.store_gradients(layer_name, grad_output[0])\n",
    "        return backward_hook\n",
    "\n",
    "\n",
    "    def store_activations(self, layer_name, output):\n",
    "        self._store_per_input(self.activations_per_input, layer_name, output)\n",
    "\n",
    "    def store_gradients(self, layer_name, gradient):\n",
    "        # Store gradients for the last epoch\n",
    "        if self.current_epoch == self.num_epochs - 1:\n",
    "            batch_size = gradient.size(0)\n",
    "            for i in range(batch_size):\n",
    "                input_index = self.batch_counter * batch_size + i\n",
    "                if input_index not in self.gradients_per_input:\n",
    "                    self.gradients_per_input[input_index] = {}\n",
    "                self.gradients_per_input[input_index][layer_name] = gradient[i].detach().cpu().numpy()\n",
    "    \n",
    "            # Increment the backward batch counter only after processing the first layer (which is the last layer in the forward pass)\n",
    "\n",
    "\n",
    "    def _store_per_input(self, storage_dict, layer_name, tensor):\n",
    "        batch_size = tensor.size(0)\n",
    "        for i in range(batch_size):\n",
    "            input_index = self.batch_counter * batch_size + i\n",
    "            if input_index not in storage_dict:\n",
    "                storage_dict[input_index] = {}\n",
    "            storage_dict[input_index][layer_name] = tensor[i].detach().cpu().numpy()\n",
    "\n",
    "        if layer_name == list(self.model.named_modules())[-1][0]:\n",
    "            self.batch_counter += 1\n",
    "\n",
    "    def start_epoch(self, epoch, num_epochs):\n",
    "        self.current_epoch = epoch\n",
    "        self.num_epochs = num_epochs\n",
    "        if epoch == num_epochs - 1:\n",
    "            self.batch_counter = 0  # Reset the batch counter on the last epoch\n",
    "\n",
    "    def get_activations(self, input_index):\n",
    "        return self.activations_per_input.get(input_index, None)\n",
    "\n",
    "    def get_gradients(self, input_index):\n",
    "        return self.gradients_per_input.get(input_index, None)\n",
    "\n",
    "    def print_structure(self):\n",
    "        print(\"Explainable Network Structure and Data Summary:\")\n",
    "\n",
    "        # Check if there is any data collected\n",
    "        if not self.activations_per_input:\n",
    "            print(\"No activations data collected.\")\n",
    "            return\n",
    "\n",
    "        if not self.gradients_per_input:\n",
    "            print(\"No gradients data collected.\")\n",
    "            return\n",
    "\n",
    "        # Print information about activations\n",
    "        print(\"\\nActivations:\")\n",
    "        first_input_activations = next(iter(self.activations_per_input.values()))\n",
    "        for layer_name, activations in first_input_activations.items():\n",
    "            num_nodes = len(activations)\n",
    "            num_data_points = len(self.activations_per_input)\n",
    "            print(f\"Layer {layer_name}: {num_nodes} nodes, {num_data_points} data points each\")\n",
    "\n",
    "        # Print information about gradients\n",
    "        print(\"\\nGradients:\")\n",
    "        first_input_gradients = next(iter(self.gradients_per_input.values()))\n",
    "        for layer_name, gradients in first_input_gradients.items():\n",
    "            num_nodes = len(gradients)\n",
    "            num_data_points = len(self.gradients_per_input)\n",
    "            print(f\"Layer {layer_name}: {num_nodes} nodes, {num_data_points} data points each\")\n",
    "\n",
    "    # TODO this uses the most recent weights\n",
    "    def get_node_input(self, layer_name, node_index, image_index):\n",
    "        if layer_name not in self.weights_per_layer:\n",
    "            raise ValueError(f\"Layer {layer_name} not found in the model\")\n",
    "\n",
    "        # Convert weights to numpy array\n",
    "        weights = self.weights_per_layer[layer_name].cpu().numpy()\n",
    "\n",
    "        if layer_name == 'fc1':\n",
    "            # For the first layer, the input is the raw image data\n",
    "            # Assuming you have a way to access the raw input images\n",
    "            pass\n",
    "        else:\n",
    "            # For subsequent layers, we use activations from the previous layer\n",
    "            prev_layer_name = self.get_previous_layer_name(layer_name)\n",
    "            prev_activations = self.activations_per_input[image_index][prev_layer_name]\n",
    "\n",
    "            # Ensure the prev_activations is a 1D array for proper dot product\n",
    "            if prev_activations.ndim > 1:\n",
    "                prev_activations = prev_activations.flatten()\n",
    "\n",
    "            # Multiply previous layer's activations by the weights for the specific node\n",
    "            input_to_node = np.dot(prev_activations, weights[node_index])\n",
    "\n",
    "        return input_to_node\n",
    "\n",
    "    def get_pre_sum_node_input(self, layer_name, node_index, image_index):\n",
    "        if layer_name not in self.weights_per_layer:\n",
    "            raise ValueError(f\"Layer {layer_name} not found in the model\")\n",
    "\n",
    "        # Convert weights to numpy array\n",
    "        weights = self.weights_per_layer[layer_name].cpu().numpy()\n",
    "\n",
    "        if layer_name == 'fc1':\n",
    "            # For the first layer, the input is the raw image data\n",
    "            # Assuming you have a way to access the raw input images\n",
    "            pass\n",
    "        else:\n",
    "            # For subsequent layers, we use activations from the previous layer\n",
    "            prev_layer_name = self.get_previous_layer_name(layer_name)\n",
    "            prev_activations = self.activations_per_input[image_index][prev_layer_name]\n",
    "\n",
    "            # Ensure the prev_activations is a 1D array for proper multiplication\n",
    "            if prev_activations.ndim > 1:\n",
    "                prev_activations = prev_activations.flatten()\n",
    "\n",
    "            # Multiply previous layer's activations by the weights for the specific node\n",
    "            pre_sum_input_to_node = prev_activations * weights[node_index]\n",
    "\n",
    "        return pre_sum_input_to_node\n",
    "    \n",
    "    def get_previous_layer_name(self, current_layer_name):\n",
    "        # Helper function to get the previous layer's name\n",
    "        layers = list(self.model.named_modules())\n",
    "        for i, (name, _) in enumerate(layers):\n",
    "            if name == current_layer_name:\n",
    "                return layers[i - 1][0] if i > 0 else None\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d90918-8c94-4e92-b15a-fd2ab33feff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTNet().to(device)\n",
    "explainable_net = ExplainableNetwork(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 2  # Adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    explainable_net.start_epoch(epoch, num_epochs)\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        if epoch == num_epochs - 1:\n",
    "            explainable_net.expected_outputs.extend(targets.cpu().numpy())\n",
    "            \n",
    "            # Convert outputs to predicted class labels\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            explainable_net.predicted_outputs.extend(predicted.cpu().numpy())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f533a9-4e95-463b-b1a9-9982fc7dbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainable_net.print_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c81d3-8fed-407e-9089-5b6d3fc2379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10\n",
    "\n",
    "print(len(explainable_net.expected_outputs))\n",
    "print(len(explainable_net.predicted_outputs))\n",
    "\n",
    "print(\"Sample of Expected Outputs:\", explainable_net.expected_outputs[:sample_size])\n",
    "print(\"Sample of Predicted Outputs:\", explainable_net.predicted_outputs[:sample_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856957d-469d-4432-8f6f-9b734fef5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "def plot_scatter_for_correct_predictions(explainable_network, layer_name, node_index):\n",
    "    activations = []\n",
    "    gradients = []\n",
    "    colors = []\n",
    "\n",
    "    # Define a color map for digits 0-9 using the new syntax\n",
    "    color_map = matplotlib.colormaps['tab10']\n",
    "\n",
    "    # Retrieve activations, gradients, and check for correct predictions\n",
    "    for input_index, (expected, predicted) in enumerate(zip(explainable_network.expected_outputs, explainable_network.predicted_outputs)):\n",
    "        if True == True:\n",
    "            activation = explainable_network.get_activations(input_index)\n",
    "            gradient = explainable_network.get_gradients(input_index)\n",
    "\n",
    "            if activation is not None and gradient is not None:\n",
    "                activations.append(activation[layer_name][node_index])\n",
    "                gradients.append(-gradient[layer_name][node_index])  # Negative of the gradient\n",
    "                colors.append(color_map(expected))  # Color code based on the correct digit\n",
    "\n",
    "    # Generate scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(15,10))  # Explicitly create figure and axes\n",
    "    scatter = ax.scatter(activations, gradients, c=colors, cmap=color_map, s=15)  # Set dot size with `s`\n",
    "    ax.set_xlabel('Activation')\n",
    "    ax.set_ylabel('Negative of Gradient')\n",
    "    ax.set_title(f'Correct Predictions Scatter Plot for {layer_name} - Node {node_index}')\n",
    "\n",
    "    # Create a colorbar with the correct axes reference\n",
    "    cbar = plt.colorbar(matplotlib.cm.ScalarMappable(cmap=color_map, norm=plt.Normalize(0, 9)), ax=ax, ticks=np.arange(0, 10))\n",
    "    cbar.set_label('Digit')\n",
    "\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_scatter_for_correct_predictions(explainable_net, 'fc2', 1)  # Example for node 5 in the first hidden layer (fc1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbdbaf-c840-4b3e-ae3a-607202255164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_for_extreme_outliers(explainable_network, layer_name, node_index, std_dev_threshold=3):\n",
    "    activations = []\n",
    "    gradients = []\n",
    "    colors = []\n",
    "\n",
    "    # Define a color map for digits 0-9\n",
    "    color_map = matplotlib.colormaps['tab10']\n",
    "\n",
    "    # Retrieve activations, gradients, and check for correct predictions\n",
    "    for input_index, (expected, predicted) in enumerate(zip(explainable_network.expected_outputs, explainable_network.predicted_outputs)):\n",
    "        if expected == predicted:\n",
    "            activation = explainable_network.get_activations(input_index)\n",
    "            gradient = explainable_network.get_gradients(input_index)\n",
    "\n",
    "            if activation is not None and gradient is not None:\n",
    "                activations.append(activation[layer_name][node_index])\n",
    "                gradients.append(-gradient[layer_name][node_index])  # Negative of the gradient\n",
    "                colors.append(color_map(expected))  # Color code based on the correct digit\n",
    "\n",
    "    # Convert lists to numpy arrays for numerical operations\n",
    "    activations = np.array(activations)\n",
    "    gradients = np.array(gradients)\n",
    "    colors = np.array(colors)\n",
    "\n",
    "    # Calculate mean and standard deviation for activations and gradients\n",
    "    activation_mean = np.mean(activations)\n",
    "    activation_std = np.std(activations)\n",
    "    gradient_mean = np.mean(gradients)\n",
    "    gradient_std = np.std(gradients)\n",
    "\n",
    "    # Apply filtering for points that are more than std_dev_threshold away in both dimensions\n",
    "    extreme_outliers = (np.abs(activations - activation_mean) > std_dev_threshold * activation_std) & \\\n",
    "                       (np.abs(gradients - gradient_mean) > std_dev_threshold * gradient_std)\n",
    "\n",
    "    # Filter activations, gradients, and colors based on the extreme outlier condition\n",
    "    activations_extreme = activations[extreme_outliers]\n",
    "    gradients_extreme = gradients[extreme_outliers]\n",
    "    colors_extreme = colors[extreme_outliers]\n",
    "\n",
    "    # Generate scatter plot with extreme outliers\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    scatter = ax.scatter(activations_extreme, gradients_extreme, c=colors_extreme, cmap=color_map, s=15)\n",
    "    ax.set_xlabel('Activation')\n",
    "    ax.set_ylabel('Negative of Gradient')\n",
    "    ax.set_title(f'Extreme Outliers Scatter Plot for {layer_name} - Node {node_index}')\n",
    "\n",
    "    # Create a colorbar\n",
    "    cbar = plt.colorbar(matplotlib.cm.ScalarMappable(cmap=color_map, norm=plt.Normalize(0, 9)), ax=ax, ticks=np.arange(0, 10))\n",
    "    cbar.set_label('Digit')\n",
    "\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "#plot_scatter_for_extreme_outliers(explainable_net, 'fc2', 3, std_dev_threshold=1.5)  # Adjust std_dev_threshold as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ada70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizes the predictions (i, j) to the total number of predictions(i, _) for all predictions\n",
    "# Returns a 2D array such that probabilities[i][j] holds the probability of the model\n",
    "# predicting last_layer[i] as last_layer[j]\n",
    "def calculate_probabilities(classifier_outcomes, label_counts):\n",
    "    probabilities = np.zeros_like(classifier_outcomes, dtype=np.float64)\n",
    "    for i in range(len(label_counts)):\n",
    "        if label_counts[i] > 0:  # Prevent division by zero\n",
    "            probabilities[i] = classifier_outcomes[i] / label_counts[i]\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf98c49-2029-4c06-b58c-3abe1962cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "final_layer_size = list(explainable_net.model.named_modules())[-1][1].out_features\n",
    "# classifier_outcomes[i][j] will store the probability of the model incorrectly classifying digit i as digit j.\n",
    "# The diagonals store the probability of a correct predicition\n",
    "classifier_outcomes = np.zeros((final_layer_size, final_layer_size), dtype=np.float64)\n",
    "label_counts = np.zeros(final_layer_size, dtype=np.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Initialize classifier_outcomes as the frequency of each prediction (label, pred)\n",
    "        for label, pred in zip(labels, predicted):\n",
    "            classifier_outcomes[label.item()][pred.item()] += 1\n",
    "            # Store the number of total attempts at predicting 'label'\n",
    "            label_counts[label.item()] += 1\n",
    "\n",
    "classifier_outcomes = calculate_probabilities(classifier_outcomes, label_counts)\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the 10000 test images: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the contents of classifier_outcomes as a percent or a probability.\n",
    "# Rounded to four decimal places\n",
    "def print_classifier_outcomes(classifier_outcomes, mode='percent'):\n",
    "    size = classifier_outcomes.shape[0]\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if mode == 'percent':\n",
    "                print(f'a {i} was classified as a {j} {classifier_outcomes[i][j] * 100:.4f}% of the time')\n",
    "            elif mode == 'probability':\n",
    "                print(f'The probability of {i} being classified as {j} is {classifier_outcomes[i][j]:.4f}')\n",
    "print_classifier_outcomes(classifier_outcomes, 'probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc8854-4017-46ef-93b3-1a182818b46f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Corrected usage with image_index as an integer\n",
    "image_index = 0  # Replace with the desired image index\n",
    "target_layer = 'fc2'\n",
    "target_node = 1  # Replace with the desired node index\n",
    "\n",
    "#input_to_node = explainable_net.get_node_input(target_layer, target_node, image_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b4719-3d45-4cdb-a35c-718962d48de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Input to node {} in layer {} for image index {}:\".format(target_node, target_layer, image_index))\n",
    "#print(input_to_node)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a7396-2853-4e03-bd0d-190f211cc12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre_sum_input_to_node = explainable_net.get_pre_sum_node_input(target_layer, target_node, image_index)\n",
    "\n",
    "# Print the result\n",
    "#print(f\"Pre-sum weighted inputs to node {target_node} in layer {target_layer} for image index {image_index}:\")\n",
    "#print(pre_sum_input_to_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c17c79-79ff-4eb0-80c0-d1e867cca5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_activation_for_node(explainable_net, image_index, layer_name, node_index):\n",
    "    # Check if the requested image index is in the stored activations\n",
    "    if image_index in explainable_net.activations_per_input:\n",
    "        image_activations = explainable_net.activations_per_input[image_index]\n",
    "        \n",
    "        # Check if the requested layer is in the activations for the image index\n",
    "        if layer_name in image_activations:\n",
    "            # Check if the requested node index is within the range of the layer's activations\n",
    "            if node_index < len(image_activations[layer_name]):\n",
    "                # Retrieve the specific activation for the node\n",
    "                activation = image_activations[layer_name][node_index]\n",
    "                print(f\"Activation for image index {image_index}, layer '{layer_name}', node {node_index}: {activation}\")\n",
    "            else:\n",
    "                print(f\"Node index {node_index} is out of range for layer '{layer_name}'.\")\n",
    "        else:\n",
    "            print(f\"Layer '{layer_name}' not found for image index {image_index}. Available layers are: {list(image_activations.keys())}\")\n",
    "    else:\n",
    "        print(f\"No activation information for image index {image_index}. Available image indices are: {list(explainable_net.activations_per_input.keys())}\")\n",
    "\n",
    "# Example usage:\n",
    "#print_activation_for_node(explainable_net, image_index=0, layer_name='fc1', node_index=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e34cb-39b4-4fa2-81d7-5ef164c301d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_activation_and_weights(explainable_net, layer_name, node_index, image_index):\n",
    "    # Check if the layer is in the model\n",
    "    if layer_name not in explainable_net.weights_per_layer:\n",
    "        raise ValueError(f\"Layer {layer_name} not found in the model\")\n",
    "\n",
    "    # Convert weights to numpy array\n",
    "    weights = explainable_net.weights_per_layer[layer_name].cpu().numpy()\n",
    "\n",
    "    # Retrieve the activations for the previous layer\n",
    "    if layer_name == 'fc1':\n",
    "        # For the first layer, we don't have previous layer activations\n",
    "        # Assuming you have a way to access the raw input images\n",
    "        print(\"Layer 'fc1' does not have previous layer activations.\")\n",
    "    else:\n",
    "        # For subsequent layers, we use activations from the previous layer\n",
    "        prev_layer_name = explainable_net.get_previous_layer_name(layer_name)\n",
    "        prev_activations = explainable_net.activations_per_input[image_index][prev_layer_name]\n",
    "\n",
    "        # Ensure the prev_activations is a 1D array for proper printing\n",
    "        if prev_activations.ndim > 1:\n",
    "            prev_activations = prev_activations.flatten()\n",
    "\n",
    "        # Get the weights for the specific node\n",
    "        node_weights = weights[node_index]\n",
    "\n",
    "        # Print the activations and weights\n",
    "        print(f\"Activations from previous layer '{prev_layer_name}' for image index {image_index}: {prev_activations}\")\n",
    "        print(f\"Weights for node {node_index} in layer '{layer_name}': {node_weights}\")\n",
    "\n",
    "# Example usage:\n",
    "#print_activation_and_weights(explainable_net, layer_name='fc3', node_index=2, image_index=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92186161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiscriminatedOutputs(explainable_network, positive, trueWithRespectToGradient):\n",
    "    activations = {}\n",
    "    extreme_outliers = []\n",
    "    gradients = {}\n",
    "    colors = []\n",
    "\n",
    "    # Define a color map for digits 0-9\n",
    "    color_map = matplotlib.colormaps['tab10']\n",
    "\n",
    "    # Retrieve activations, gradients, and check for correct predictions\n",
    "    for input_index, (expected, predicted) in enumerate(zip(explainable_network.expected_outputs, explainable_network.predicted_outputs)):\n",
    "        if True == True:\n",
    "            activation = explainable_network.get_activations(input_index)\n",
    "            gradient = explainable_network.get_gradients(input_index)\n",
    "\n",
    "            if activation is not None and gradient is not None:\n",
    "                activations[input_index] = activation['fc2'][1]\n",
    "                gradients[input_index] = -gradient['fc2'][1] # Negative of the gradient\n",
    "                colors.append(color_map(expected))  # Color code based on the correct digit\n",
    "\n",
    "    # Convert lists to numpy arrays for numerical operations\n",
    "    activationArray = np.array(list(activations.values()))\n",
    "    gradientsArray = np.array(list(gradients.values()))\n",
    "    colors = np.array(colors)\n",
    "\n",
    "    # Calculate mean and standard deviation for activations and gradients\n",
    "    activation_mean = np.mean(activationArray)\n",
    "    activation_std = np.std(activationArray)\n",
    "    gradient_mean = np.mean(gradientsArray)\n",
    "    gradient_std = np.std(gradientsArray)\n",
    "\n",
    "    # Apply filtering for points that are more than std_dev_threshold away in both dimensions\n",
    "    if positive and trueWithRespectToGradient:\n",
    "        for keyA, valueA in activations.items():\n",
    "            if ((valueA - activation_mean) > 1.5 * activation_std) and ((gradients[keyA] - gradient_mean) > 1.5 * gradient_std):\n",
    "                extreme_outliers.append(keyA)\n",
    "    elif not positive and not trueWithRespectToGradient:\n",
    "        for keyA, valueA in activations.items():\n",
    "            if ((valueA - activation_mean) < 1.5 * activation_std) and ((gradients[keyA] - gradient_mean) < 1.5 * gradient_std):\n",
    "                extreme_outliers.append(keyA)\n",
    "                    \n",
    "    return extreme_outliers\n",
    "truePos = DiscriminatedOutputs(explainable_net, True, True)\n",
    "trueNeg = DiscriminatedOutputs(explainable_net, False, True)\n",
    "print(len(trueNeg))\n",
    "\n",
    "def display_image_grid(images, rows, cols):\n",
    "    grid = torchvision.utils.make_grid(images, nrow=cols)\n",
    "    grid = grid / 2 + 0.5  # Unnormalize\n",
    "    plt.figure(figsize=(15, 15))  # Adjust the size as needed\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "# Number of images per grid\n",
    "images_per_grid = 128  # for example, a 4x4 grid\n",
    "\n",
    "# Calculate rows and columns for the grid\n",
    "cols = 10  # Number of columns\n",
    "rows = images_per_grid // cols\n",
    "\n",
    "# Display the images in grids\n",
    "for i in range(0, len(truePos), images_per_grid):\n",
    "    selected_indices = truePos[i:i+images_per_grid]\n",
    "    selected_images = torch.stack([all_images[index] for index in selected_indices])\n",
    "    display_image_grid(selected_images, rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e280c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiscriminatedOutputs(explainable_network, positive, trueWithRespectToGradient):\n",
    "    activations = []\n",
    "    gradients = []\n",
    "    colors = []\n",
    "\n",
    "    # Define a color map for digits 0-9\n",
    "    color_map = matplotlib.colormaps['tab10']\n",
    "\n",
    "    # Retrieve activations, gradients, and check for correct predictions\n",
    "    for input_index, (expected, predicted) in enumerate(zip(explainable_network.expected_outputs, explainable_network.predicted_outputs)):\n",
    "        if expected == predicted:\n",
    "            activation = explainable_network.get_activations(input_index)\n",
    "            gradient = explainable_network.get_gradients(input_index)\n",
    "\n",
    "            if activation is not None and gradient is not None:\n",
    "                activations.append(activation['fc2'][1])\n",
    "                gradients.append(-gradient['fc2'][1])  # Negative of the gradient\n",
    "                colors.append(color_map(expected))  # Color code based on the correct digit\n",
    "\n",
    "    # Convert lists to numpy arrays for numerical operations\n",
    "    activations = np.array(activations)\n",
    "    gradients = np.array(gradients)\n",
    "    colors = np.array(colors)\n",
    "\n",
    "    # Calculate mean and standard deviation for activations and gradients\n",
    "    activation_mean = np.mean(activations)\n",
    "    activation_std = np.std(activations)\n",
    "    gradient_mean = np.mean(gradients)\n",
    "    gradient_std = np.std(gradients)\n",
    "\n",
    "    # Apply filtering for points that are more than std_dev_threshold away in both dimensions\n",
    "    extreme_outliers = ((activations - activation_mean) > 1.5 * activation_std) & \\\n",
    "                       ((gradients - gradient_mean) > 1.5 * gradient_std)\n",
    "\n",
    "    # Filter activations, gradients, and colors based on the extreme outlier condition\n",
    "    activations_extreme = activations[extreme_outliers]\n",
    "    gradients_extreme = gradients[extreme_outliers]\n",
    "    colors_extreme = colors[extreme_outliers]\n",
    "\n",
    "    print(len(activations_extreme))\n",
    "    # Generate scatter plot with extreme outliers\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    scatter = ax.scatter(activations_extreme, gradients_extreme, c=colors_extreme, cmap=color_map, s=15)\n",
    "    ax.set_xlabel('Activation')\n",
    "    ax.set_ylabel('Negative of Gradient')\n",
    "    ax.set_title(f'Extreme Outliers Scatter Plot for fc2 - Node 1')\n",
    "\n",
    "    # Create a colorbar\n",
    "    cbar = plt.colorbar(matplotlib.cm.ScalarMappable(cmap=color_map, norm=plt.Normalize(0, 9)), ax=ax, ticks=np.arange(0, 10))\n",
    "    cbar.set_label('Digit')\n",
    "\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "DiscriminatedOutputs(explainable_net, True, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b683fa-ed85-4ee5-9c47-f274fd967221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.shape(explainable_net.predicted_outputs))\n",
    "def visualizePreSumInput(visualizingArray, targetLayer, targetNode, imageIndex):\n",
    "    pixelColoringMatrix = explainable_net.get_pre_sum_node_input(targetLayer, targetNode, imageIndex)\n",
    "    # for i in range(len(pixelColoringMatrix)):\n",
    "    #     if pixelColoringMatrix[i] > 0:\n",
    "    #         pixelColoringMatrix[i] = 1\n",
    "    #     else:\n",
    "    #         pixelColoringMatrix[i] = -1\n",
    "#visualizePreSumInput(explainable_net, 'fc2', 1, 0)\n",
    "plot_scatter_for_extreme_outliers(explainable_net, 'fc2', 1, std_dev_threshold=1.5)  # Adjust std_dev_threshold as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754586f-c743-4c2e-b4a4-08274e581ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_subset = [all_images[i] for i in truePos]\n",
    "\n",
    "# Flatten the images\n",
    "flattened_images = torch.stack(images_subset).view(len(images_subset), -1).numpy()\n",
    "\n",
    "# Perform PCA to reduce dimensions\n",
    "pca = PCA(n_components=2)  # reduce to 2 dimensions for visualization\n",
    "reduced_images = pca.fit_transform(flattened_images)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(reduced_images[:, 0], reduced_images[:, 1], s=50)\n",
    "plt.title(\"PCA Reduced MNIST Images\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90a175-8b5d-4cdd-8fc1-80862833bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_subset = torch.stack([all_images[i] for i in truePos])\n",
    "average_image = images_subset.float().mean(dim=0).squeeze()\n",
    "plt.imshow(average_image, cmap='gray')\n",
    "plt.title(\"Average Image\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a27205-2204-4a50-a598-ecc752d14fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_image = (average_image - average_image.min()) / (average_image.max() - average_image.min())\n",
    "\n",
    "# Apply a power law transformation to increase contrast, emphasizing the bright pixels\n",
    "# Squaring the normalized pixel values will make high values brighter and low values dimmer\n",
    "emphasized_image = normalized_image ** 4\n",
    "\n",
    "# Plot the emphasized average image\n",
    "plt.imshow(emphasized_image, cmap='gray')\n",
    "plt.title(\"Emphasized Average Image\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859761c-8b6f-481f-83d5-19cd66a19c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create dummy data for dataset1 and dataset2\n",
    "# Let's assume each sample has 784 features (like flattened MNIST images)\n",
    "dataset1 = torch.rand(100, 784)  # 100 samples from class 0\n",
    "dataset2 = torch.rand(100, 784)  # 100 samples from class 1\n",
    "\n",
    "\n",
    "labels1 = torch.zeros(100, dtype=torch.float32)  # Labels for dataset1\n",
    "labels2 = torch.ones(100, dtype=torch.float32)   # Labels for dataset2\n",
    "\n",
    "# Combine datasets\n",
    "combined_dataset = torch.cat([dataset1, dataset2], dim=0)\n",
    "combined_labels = torch.cat([labels1, labels2], dim=0)\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "dataset = TensorDataset(combined_dataset, combined_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.explainable_node.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5  # For demonstration, adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model.forward_with_explainable(inputs).squeeze()  # Get outputs from the explainable node\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5082f5-f0a4-4a71-891c-5ac63d1e8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = all_images[1].to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Forward pass to get both outputs\n",
    "with torch.no_grad():\n",
    "    regular_output, explainable_output = model(inputs, return_explainable=True)\n",
    "\n",
    "print(\"Regular Output:\", regular_output)\n",
    "print(\"Explainable Output:\", explainable_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908b789-33ba-4f08-b71c-54e2df89ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def plot_extreme_outliers(explainable_network, layer_name, node_index, std_dev_threshold=3, discriminate_classes=[-1,-1], Correct_pred_only=False):\n",
    "    activations = []\n",
    "    gradients = []\n",
    "    colors = []\n",
    "    labels = []\n",
    "    classA = discriminate_classes[0]\n",
    "    classB = discriminate_classes[1]\n",
    "    \n",
    "    # Define a color map for digits 0-9\n",
    "    color_map = matplotlib.colormaps['tab10']\n",
    "\n",
    "    # Retrieve activations, gradients, and check for correct predictions\n",
    "    for input_index, (expected, predicted) in enumerate(zip(explainable_network.expected_outputs, explainable_network.predicted_outputs)):\n",
    "        if expected == predicted or not Correct_pred_only:\n",
    "            activation = explainable_network.get_activations(input_index)\n",
    "            gradient = explainable_network.get_gradients(input_index)\n",
    "\n",
    "            if activation is not None and gradient is not None:\n",
    "                activations.append(activation[layer_name][node_index])\n",
    "                gradients.append(-gradient[layer_name][node_index])  # Negative of the gradient\n",
    "                colors.append(color_map(expected))  # Color code based on the correct digit\n",
    "                labels.append(expected)\n",
    "            \n",
    "\n",
    "    # Convert lists to numpy arrays for numerical operations\n",
    "    activations = np.array(activations)\n",
    "    gradients = np.array(gradients)\n",
    "    labels = np.array(labels)\n",
    "    colors = np.array(colors)\n",
    "\n",
    "    # Calculate mean and standard deviation for activations and gradients\n",
    "    activation_mean = np.mean(activations)\n",
    "    activation_std = np.std(activations)\n",
    "    gradient_mean = np.mean(gradients)\n",
    "    gradient_std = np.std(gradients)\n",
    "\n",
    "    # Apply filtering for points that are more than std_dev_threshold away in both dimensions\n",
    "    extreme_outliers = (np.abs(activations - activation_mean) > std_dev_threshold * activation_std) & \\\n",
    "                       (np.abs(gradients - gradient_mean) > std_dev_threshold * gradient_std)\n",
    "\n",
    "    # Filter activations, gradients, and colors based on the extreme outlier condition\n",
    "    activations_extreme = activations[extreme_outliers]\n",
    "    gradients_extreme = gradients[extreme_outliers]\n",
    "    labels_extreme = labels[extreme_outliers]\n",
    "    colors_extreme = colors[extreme_outliers]\n",
    "\n",
    "    # Create Dataframe for easy use\n",
    "    df = pd.DataFrame({'Activations': activations_extreme, 'Gradients': gradients_extreme, 'Labels': labels_extreme})\n",
    "    \n",
    "    if classA > -1 and classB > -1:\n",
    "        #condition = np.logical_or(colors_extreme[labels == classA], colors_extreme[labels == classB])\n",
    "        colors_extreme = colors_extreme[df['Labels'].isin([classA, classB])]\n",
    "        df = df[df['Labels'].isin([classA, classB])]\n",
    "\n",
    "    # Generate scatter plot with extreme outliers\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    scatter = ax.scatter(df.loc[:, ['Activations']], df.loc[:, ['Gradients']], c= colors_extreme, cmap=color_map, s=15)\n",
    "    ax.set_xlabel('Activation')\n",
    "    ax.set_ylabel('Negative of Gradient')\n",
    "    ax.set_title(f'Extreme Outliers Scatter Plot for {layer_name} - Node {node_index}')\n",
    "\n",
    "    # Create a colorbar\n",
    "    cbar = plt.colorbar(matplotlib.cm.ScalarMappable(cmap=color_map, norm=plt.Normalize(0, 9)), ax=ax, ticks=np.arange(0, 10))\n",
    "    cbar.set_label('Digit')\n",
    "\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "plot_extreme_outliers(explainable_net, 'fc3', 3, std_dev_threshold=1, Correct_pred_only=False)  # Adjust std_dev_threshold as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce092ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def plot_extreme_outliers_quad(explainable_network, layer_name, node_index, quadrant, std_dev_threshold=3, selected_class=-1):\n",
    "    activations = []\n",
    "    gradients = []\n",
    "    labels = []\n",
    "    imgIndx = []\n",
    "    colors = []\n",
    "    \n",
    "     # Define a color map for digits 0-9\n",
    "    color_map = matplotlib.colormaps['tab10']\n",
    "\n",
    "    # Retrieve activations, gradients, and check for correct predictions\n",
    "    for input_index, (expected, predicted) in enumerate(zip(explainable_network.expected_outputs, explainable_network.predicted_outputs)):\n",
    "        #if expected == predicted: do we want to filter this?\n",
    "        activation = explainable_network.get_activations(input_index)\n",
    "        gradient = explainable_network.get_gradients(input_index)\n",
    "\n",
    "        if activation is not None and gradient is not None:\n",
    "            activations.append(activation[layer_name][node_index])\n",
    "            gradients.append(-gradient[layer_name][node_index])  # Negative of the gradient\n",
    "            labels.append(expected)\n",
    "            imgIndx.append(input_index)\n",
    "            colors.append(color_map(expected))  # Color code based on the correct digit\n",
    "            \n",
    "\n",
    "    # Convert lists to numpy arrays for numerical operations\n",
    "    activations = np.array(activations)\n",
    "    gradients = np.array(gradients)\n",
    "    labels = np.array(labels)\n",
    "    imgIndx = np.array(imgIndx)\n",
    "    colors = np.array(colors)\n",
    "\n",
    "\n",
    "    # Calculate mean and standard deviation for activations and gradients\n",
    "    activation_mean = np.mean(activations)\n",
    "    activation_std = np.std(activations)\n",
    "    gradient_mean = np.mean(gradients)\n",
    "    gradient_std = np.std(gradients)\n",
    "\n",
    "    # Apply filtering for points that are more than std_dev_threshold away in both dimensions\n",
    "    extreme_outliers = (np.abs(activations - activation_mean) > std_dev_threshold * activation_std) & \\\n",
    "                       (np.abs(gradients - gradient_mean) > std_dev_threshold * gradient_std)\n",
    "\n",
    "    # Filter activations, gradients, and colors based on the extreme outlier condition\n",
    "    activations_extreme = activations[extreme_outliers]\n",
    "    gradients_extreme = gradients[extreme_outliers]\n",
    "    labels_extreme = labels[extreme_outliers]\n",
    "    colors_extreme = colors[extreme_outliers]\n",
    "    imgIndx = imgIndx[extreme_outliers]\n",
    "\n",
    "    # Create Dataframe for easy use\n",
    "    df = pd.DataFrame({'Index':imgIndx,'Activations': activations_extreme, 'Gradients': gradients_extreme, 'Labels': labels_extreme})\n",
    "    \n",
    "    if selected_class > -1:\n",
    "        colors_extreme = colors_extreme[df['Labels'] == selected_class]\n",
    "        df = df[df['Labels'] == selected_class]\n",
    "        \n",
    "    if quadrant == 1:\n",
    "        colors_extreme = colors_extreme[df['Gradients'] > 0]\n",
    "        df = df[df['Gradients'] > 0]\n",
    "        colors_extreme = colors_extreme[df['Activations'] > 0]\n",
    "        df = df[df['Activations'] > 0]\n",
    "    elif quadrant == 2:\n",
    "        colors_extreme = colors_extreme[df['Gradients'] > 0]\n",
    "        df = df[df['Gradients'] > 0]\n",
    "        colors_extreme = colors_extreme[df['Activations'] < 0]\n",
    "        df = df[df['Activations'] < 0]\n",
    "        \n",
    "    elif quadrant == 3:\n",
    "        colors_extreme = colors_extreme[df['Gradients'] < 0]\n",
    "        df = df[df['Gradients'] < 0]\n",
    "        colors_extreme = colors_extreme[df['Activations'] < 0]\n",
    "        df = df[df['Activations'] < 0]\n",
    "        \n",
    "    elif quadrant == 4:\n",
    "        colors_extreme = colors_extreme[df['Gradients'] < 0]\n",
    "        df = df[df['Gradients'] < 0]\n",
    "        colors_extreme = colors_extreme[df['Activations'] > 0]\n",
    "        df = df[df['Activations'] > 0]\n",
    "        \n",
    "    # Generate scatter plot with extreme outliers\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    scatter = ax.scatter(df.loc[:, ['Activations']], df.loc[:, ['Gradients']], c=colors_extreme, cmap=color_map, s=15)\n",
    "    ax.set_xlabel('Activation')\n",
    "    ax.set_ylabel('Negative of Gradient')\n",
    "    ax.set_title(f'Extreme Outliers Scatter Plot for {layer_name} - Node {node_index}')\n",
    "\n",
    "    # Create a colorbar\n",
    "    cbar = plt.colorbar(matplotlib.cm.ScalarMappable(cmap=color_map, norm=plt.Normalize(0, 9)), ax=ax, ticks=np.arange(0, 10))\n",
    "    cbar.set_label('Digit')\n",
    "\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "plot_extreme_outliers_quad(explainable_net, 'fc3', 3, std_dev_threshold=1, quadrant= 4, selected_class=2)  # Adjust std_dev_threshold as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extreme_outliers_quad(explainable_network, layer_name, node_index, quadrant, std_dev_threshold=3, selected_class=-1):\n",
    "    activations = []\n",
    "    gradients = []\n",
    "    labels = []\n",
    "    imgIndx = []\n",
    "\n",
    "    # Retrieve activations, gradients, and check for correct predictions\n",
    "    for input_index, (expected, predicted) in enumerate(zip(explainable_network.expected_outputs, explainable_network.predicted_outputs)):\n",
    "        #if expected == predicted: do we want to filter this?\n",
    "        activation = explainable_network.get_activations(input_index)\n",
    "        gradient = explainable_network.get_gradients(input_index)\n",
    "\n",
    "        if activation is not None and gradient is not None:\n",
    "            activations.append(activation[layer_name][node_index])\n",
    "            gradients.append(-gradient[layer_name][node_index])  # Negative of the gradient\n",
    "            labels.append(expected)\n",
    "            imgIndx.append(input_index)\n",
    "            \n",
    "\n",
    "    # Convert lists to numpy arrays for numerical operations\n",
    "    activations = np.array(activations)\n",
    "    gradients = np.array(gradients)\n",
    "    labels = np.array(labels)\n",
    "    imgIndx = np.array(imgIndx)\n",
    "\n",
    "\n",
    "    # Calculate mean and standard deviation for activations and gradients\n",
    "    activation_mean = np.mean(activations)\n",
    "    activation_std = np.std(activations)\n",
    "    gradient_mean = np.mean(gradients)\n",
    "    gradient_std = np.std(gradients)\n",
    "\n",
    "    # Apply filtering for points that are more than std_dev_threshold away in both dimensions\n",
    "    extreme_outliers = (np.abs(activations - activation_mean) > std_dev_threshold * activation_std) & \\\n",
    "                       (np.abs(gradients - gradient_mean) > std_dev_threshold * gradient_std)\n",
    "\n",
    "    # Filter activations, gradients, and colors based on the extreme outlier condition\n",
    "    activations_extreme = activations[extreme_outliers]\n",
    "    gradients_extreme = gradients[extreme_outliers]\n",
    "    labels_extreme = labels[extreme_outliers]\n",
    "    imgIndx = imgIndx[extreme_outliers]\n",
    "\n",
    "    # Create Dataframe for easy use\n",
    "    df = pd.DataFrame({'Index':imgIndx,'Activations': activations_extreme, 'Gradients': gradients_extreme, 'Labels': labels_extreme})\n",
    "    \n",
    "    if selected_class > -1:\n",
    "        df = df[df['Labels'] == selected_class]\n",
    "        \n",
    "    if quadrant == 1:\n",
    "        df = df[df['Activations'] > 0]\n",
    "        df = df[df['Gradients'] > 0]\n",
    "        \n",
    "    elif quadrant == 2:\n",
    "        df = df[df['Activations'] < 0]\n",
    "        df = df[df['Gradients'] > 0]\n",
    "        \n",
    "    elif quadrant == 3:\n",
    "        df = df[df['Activations'] < 0]\n",
    "        df = df[df['Gradients'] < 0]\n",
    "        \n",
    "    elif quadrant == 4:\n",
    "        df = df[df['Activations'] > 0]\n",
    "        df = df[df['Gradients'] < 0]\n",
    "    \n",
    "    return df['Index'].values\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "extreme_outliers_quad(explainable_net, 'fc3', 3, std_dev_threshold=1, quadrant= 2)  # Adjust std_dev_threshold as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2082a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
