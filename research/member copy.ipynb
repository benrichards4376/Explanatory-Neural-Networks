{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVKu-Zc4ht5B"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLGbyzp-rW7x"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "batchnum = 64\n",
    "# Transform to convert images to PyTorch tensors and normalize them\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data for MNIST\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchnum, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "By3gBMt2rZ4M"
   },
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.layers = nn.ModuleDict({\n",
    "            'fc1': nn.Linear(784, 128),\n",
    "            'fc2': nn.Linear(128, 64),\n",
    "            'fc3': nn.Linear(64, 10)  # Output layer for 10 classes\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        for i in range(1, 4):\n",
    "            layer = self.layers[f'fc{i}']\n",
    "            x = F.relu(layer(x)) if i != 3 else layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_layer_name(self, module):\n",
    "        for name, mod in self.layers.items():\n",
    "            if mod is module:\n",
    "                return name\n",
    "        return None\n",
    "\n",
    "\n",
    "class ExplainableNetwork:\n",
    "    def __init__(self, model):\n",
    "        self.model = model  # Store the reference to the model\n",
    "        self.gradients = {}\n",
    "        self.current_epoch = 0\n",
    "        self.node_inputs = []\n",
    "        self.activations_stats = {}\n",
    "        self.activations_per_input = {}\n",
    "        self.highest_activations = {}\n",
    "        self.lowest_activations = {}\n",
    "        self.current_expected_output = None\n",
    "        self.batch_counter = 0\n",
    "        self.last_layer_key = list(model.layers.keys())[-1]\n",
    "    \n",
    "\n",
    "    def input_hook(self, module, num_epochs, input, output):\n",
    "        if self.current_epoch == num_epochs - 1:\n",
    "            layer_name = self.model.get_layer_name(module) # Get the layer name\n",
    "            \n",
    "            \n",
    "            batch_size = output.size(0)\n",
    "            # Loop through each sample in the batch to get individual activations\n",
    "            for i in range(batch_size):\n",
    "                # Calculate the global index of the image in the dataset\n",
    "                image_index = batch_size * self.batch_counter + i\n",
    "                if image_index not in self.activations_per_input:\n",
    "                    self.activations_per_input[image_index] = {}\n",
    "        \n",
    "                # Store the activations for the current layer and image\n",
    "                self.activations_per_input[image_index][layer_name] = output[i].detach().cpu().numpy()\n",
    "                \n",
    "            if layer_name == self.last_layer_key:\n",
    "                self.batch_counter += 1\n",
    "\n",
    "            for i in range(input[0].size(dim=0)):\n",
    "                if np.shape(input[0][i]) == torch.Size([784]):\n",
    "                    image = input[0][i].detach().reshape(28, 28).cpu().numpy()\n",
    "                    self.node_inputs.append((layer_name, i, image))\n",
    "                    \n",
    "    def backward_hook(self, module, grad_input, grad_output):\n",
    "        # grad_output[0] will contain the gradient of the output with respect to the loss\n",
    "        self.gradients[module] = grad_output[0].detach().tolist()\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        self.current_epoch = epoch\n",
    "    def get_extreme_activations(self, dev=0):\n",
    "        self.calculate_activations_stats()\n",
    "        self.find_extreme_activations(dev)\n",
    "\n",
    "    def calculate_activations_stats(self):\n",
    "        self.activations_stats = {}\n",
    "        for image_index, layers_activations in self.activations_per_input.items():\n",
    "            for layer_name, activations in layers_activations.items():\n",
    "                if layer_name not in self.activations_stats:\n",
    "                    self.activations_stats[layer_name] = []\n",
    "\n",
    "                self.activations_stats[layer_name].append(activations)\n",
    "\n",
    "        for layer_name, activations_list in self.activations_stats.items():\n",
    "            self.activations_stats[layer_name] = {\n",
    "                'mean': np.mean(activations_list, axis=0),\n",
    "                'std': np.std(activations_list, axis=0)\n",
    "            }\n",
    "    def find_extreme_activations(self, dev=1):\n",
    "\n",
    "        for image_index, layers_activations in self.activations_per_input.items():\n",
    "            for layer_name, activations in layers_activations.items():\n",
    "                if layer_name not in self.highest_activations:\n",
    "                    self.highest_activations[layer_name] = []\n",
    "                if layer_name not in self.lowest_activations:\n",
    "                    self.lowest_activations[layer_name] = []\n",
    "\n",
    "                mean = self.activations_stats[layer_name]['mean']\n",
    "                std = self.activations_stats[layer_name]['std']\n",
    "                high_threshold = mean + dev * std\n",
    "                low_threshold = mean - dev * std\n",
    "\n",
    "                high_activations = activations[(activations > high_threshold) & (activations > 0)]\n",
    "                low_activations = activations[(activations < low_threshold) & (activations < 0)]\n",
    "                if high_activations.size > 0:\n",
    "                    self.highest_activations[layer_name].append(high_activations)\n",
    "                if low_activations.size > 0:\n",
    "                    self.lowest_activations[layer_name].append(low_activations)\n",
    "                \n",
    "    def visualize_activations_for_input(self, image_index, layers=None, node_index=None, color='ro'):\n",
    "        if layers is None:\n",
    "            layers = ['fc1', 'fc2', 'fc3']\n",
    "\n",
    "        if node_index is not None:\n",
    "            activations = [self.activations_per_input[idx][layers[0]][node_index] \n",
    "                            for idx in self.activations_per_input if layers[0] in self.activations_per_input[idx]]\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(activations, color)\n",
    "            plt.title(f'Activations of Neuron {node_index} in {layers[0]} Across Images')\n",
    "            plt.xlabel('Image Index')\n",
    "            plt.ylabel('Activation')\n",
    "            plt.show()\n",
    "        else:\n",
    "            individual_activations = self.activations_per_input.get(image_index, {})\n",
    "            for layer in layers:\n",
    "                layer_activations = individual_activations.get(layer, None)\n",
    "                if layer_activations is not None:\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    plt.scatter(range(len(layer_activations)), layer_activations, label=layer)\n",
    "                    plt.title(f'Activations in Layer {layer} for Image {image_index}')  # Set title with layer name\n",
    "                    plt.xlabel('Neuron Index')\n",
    "                    plt.ylabel('Activation')\n",
    "                    plt.legend()\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    def print_all_activations(self):\n",
    "        for image_index, layers_dict in self.activations_per_input.items():\n",
    "            print(f\"Image Index: {image_index}\")\n",
    "            for layer_name, activations in layers_dict.items():\n",
    "                  # Only print if layer name is 'fc2'\n",
    "                print(f\"  Layer Name: {layer_name}\")\n",
    "                print(f\"    Shape of Activations: {activations.shape}\")\n",
    "                print(f\"    Sample Activations: {activations[:5]}\")  # Print first 5 activations as a sample\n",
    "\n",
    "    def print_highest_activations(self):\n",
    "        for layer_name, activations in self.highest_activations.items():\n",
    "            print(f\"Layer: {layer_name}\")\n",
    "            for node_index, node_activations in enumerate(activations):\n",
    "                print(f\"\\tNode {node_index}:\")\n",
    "                for activation in node_activations:\n",
    "                    print(f\"\\t\\t{activation}\")\n",
    "            print()\n",
    "\n",
    "    def print_lowest_activations(self):\n",
    "        for layer_name, activations in self.lowest_activations.items():\n",
    "            print(f\"Layer: {layer_name}\")\n",
    "            for node_index, node_activations in enumerate(activations):\n",
    "                print(f\"\\tNode {node_index}:\")\n",
    "                for activation in node_activations:\n",
    "                    print(f\"\\t\\t{activation}\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = MNISTNet().to(device)\n",
    "xNetwork = ExplainableNetwork(model)\n",
    "\n",
    "\n",
    "\n",
    "# Register forward and backward hooks for each layer\n",
    "for layer_name in model.layers.keys():\n",
    "    layer = model.layers[layer_name]\n",
    "\n",
    "    # Forward hook\n",
    "    layer.register_forward_hook(\n",
    "       lambda module, input, output, x_Network=xNetwork: xNetwork.input_hook(module, num_epochs, input, output)\n",
    "    )\n",
    "\n",
    "    # Backward hook\n",
    "    layer.register_backward_hook(\n",
    "        lambda module, grad_input, grad_output, x_Network=xNetwork: xNetwork.backward_hook(module, grad_input, grad_output)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Txo0Ag1yrk0G",
    "outputId": "7428e951-46fd-4ad7-e1a8-f0fe2c37bd32"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 2\n",
    "total_batches = len(trainloader)  # Total number of batches\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch \" + str(epoch + 1))\n",
    "    \n",
    "    # Set the current epoch in ExplainableNetwork\n",
    "    xNetwork.set_epoch(epoch)\n",
    "    xNetwork.batch_counter = 0\n",
    "\n",
    "    for batch_num, (inputs, labels) in enumerate(trainloader, 1):  # Start enumeration from 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Transfer to GPU\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # You might want to print a new line after each epoch for better readability\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xNetwork.get_extreme_activations(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xNetwork.print_highest_activations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xNetwork.print_lowest_activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays all activations on all layers for a given image index\n",
    "xNetwork.visualize_activations_for_input(5)\n",
    "# Displays all activations on a given layer for a given image index\n",
    "# xNetwork.visualize_activations_for_input(0, layers=['fc3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xNetwork.print_all_activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(xNetwork.activations_per_input.keys())[:5]) \n",
    "print(len(list(xNetwork.activations_per_input.keys())))\n",
    "print(model.layers.keys())\n",
    "total_images = len(trainloader.dataset)\n",
    "print(f\"Total images in the dataset: {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchnum, shuffle=False)\n",
    "\n",
    "\n",
    "def test_accuracy(model, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Evaluate the Model\n",
    "accuracy = test_accuracy(model, testloader)\n",
    "print(f'Accuracy of the model on the test images: {accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
