{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267543df-239a-41ab-a2aa-7f38f75b9dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mazor/nn/nn/lib64/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c354b8-15ff-40b9-8881-9a9f75eceb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Set the seed for reproducibility.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  # Set the seed for numpy for reproducibility\n",
    "    random.seed(seed)  # Set Python random seed\n",
    "    # Ensures that CUDA operations are deterministic\n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Example: Setting the seed to 42\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d860fae1-be90-4c73-a845-b353a25f7061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "batch_size = 32\n",
    "# Transform to convert images to PyTorch tensors and normalize them\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data for MNIST\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a05dc72-341a-4f84-8184-6ff3005e1bc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_indices = []\n",
    "\n",
    "for i, (images, labels) in enumerate(trainloader):\n",
    "    all_images.extend(images)\n",
    "    all_indices.extend(range(i * len(images), (i + 1) * len(images)))\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "all_images = torch.stack(all_images)\n",
    "all_indices = torch.tensor(all_indices)\n",
    "\n",
    "\n",
    "\n",
    "# Function to display an image given its index\n",
    "def imshow_by_index(index):\n",
    "    img = all_images[index] / 2 + 0.5  # Unnormalize\n",
    "    plt.imshow(img.permute(1, 2, 0))  # Convert from Tensor image\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b1268a-4501-484a-b05d-33fcf1c529a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        # Assuming MNIST images are 1x28x28 (channels x width x height)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2) # Output: 32x28x28\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2) # Output: 64x14x14\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # Output: 64x7x7 after pooling\n",
    "        \n",
    "        # Flatten: 64*7*7 = 3136 features\n",
    "        self.fc1 = nn.Linear(3136, 128) # Fully connected layer\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64) # Additional fully connected layer\n",
    "        self.fc3 = nn.Linear(64, 10) # Final layer for classifying into 10 classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x1 = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x1))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdecabee-49f9-4ea6-8ac4-47e4f77ea882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.14668731273297453\n",
      "Epoch 2, Loss: 0.048709439629817886\n",
      "Epoch 3, Loss: 0.033210775474544305\n",
      "Epoch 4, Loss: 0.02455204180046809\n",
      "Epoch 5, Loss: 0.019545637330693293\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network and move it to the device\n",
    "net = MNISTNet().to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "def train(net, trainloader, device, criterion, optimizer, epochs=5):\n",
    "    net.train()\n",
    "    for epoch in range(epochs):  \n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "# Testing loop\n",
    "def test(net, testloader, device):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %f %%' % (100 * correct / total))\n",
    "\n",
    "# Train and test the network\n",
    "train(net, trainloader, device, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef21e8e0-cb89-451b-8c54-25be910eae7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99.020000 %\n"
     ]
    }
   ],
   "source": [
    "test(net, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921897cd-fc78-4e80-aa22-f4a5cd625187",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableNode(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(TrainableNode, self).__init__()\n",
    "        self.linear = nn.Linear(input_features, output_features)\n",
    "        self.is_explainable = True\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Step 1: Add the new layer\n",
    "net.explainable_node = TrainableNode(128, 1).to(device)\n",
    "\n",
    "# Step 2: Dynamically override the forward method\n",
    "def new_forward(self, x, return_explainable=False):\n",
    "    x = F.relu(self.conv1(x))\n",
    "    x = self.pool(x)\n",
    "    x = F.relu(self.conv2(x))\n",
    "    x = self.pool(x)\n",
    "    \n",
    "    # Flatten the output for the fully connected layers\n",
    "    x = x.view(x.size(0), -1)\n",
    "    \n",
    "    x1 = F.relu(self.fc1(x))\n",
    "    \n",
    "    if return_explainable:\n",
    "        explainable_output = self.explainable_node(x1).squeeze()\n",
    "    \n",
    "    x = F.relu(self.fc2(x1))\n",
    "    x = self.fc3(x)\n",
    "    \n",
    "    if return_explainable:\n",
    "        return x, explainable_output\n",
    "    return x\n",
    "\n",
    "# Assign the new forward method to the net instance\n",
    "net.forward = new_forward.__get__(net, MNISTNet)\n",
    "\n",
    "# Optionally, if you want to directly use the explainable forward method without affecting the original forward method\n",
    "def forward_with_explainable(self, x):\n",
    "    # This example assumes you want to pass the original input through the explainable node directly\n",
    "    # Adjust accordingly if you meant something different\n",
    "    explainable_output = self.explainable_node(x).squeeze()\n",
    "    return explainable_output\n",
    "\n",
    "# Assign this method as well if needed\n",
    "net.forward_with_explainable = forward_with_explainable.__get__(net, MNISTNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51adc2f5-d601-4c06-a9e0-513e28311afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainableNetwork:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.activations_per_input = {}\n",
    "        self.gradients_per_input = {} \n",
    "        self.batch_counter = 0\n",
    "        self.layer_names = []\n",
    "        self.explainable_module_names = set()\n",
    "        explainable_module_names = set()\n",
    "        for name, module in model.named_modules():\n",
    "            if getattr(module, 'is_explainable', False):\n",
    "                explainable_module_names.add(name)\n",
    "        for name, module in model.named_modules():\n",
    "            if name and not any(part in explainable_module_names for part in name.split('.')):\n",
    "                self.layer_names.append(name)\n",
    "            elif name:\n",
    "                self.explainable_module_names.add(name)\n",
    "\n",
    "        self.expected_outputs = []\n",
    "        self.predicted_outputs = []\n",
    "\n",
    "        self.hook_handles = [] \n",
    "        \n",
    "        self.enable_hooks()\n",
    "        \n",
    "    # def getNonExpLayers(model):\n",
    "    #     layers = []\n",
    "    #     for name, module in model.named_modules():\n",
    "    #         if name != '' and not isinstance(module, TrainableNode):\n",
    "    #             layers.append(name)\n",
    "    #     return layers\n",
    "\n",
    "    # Register hooks for each layer\n",
    "    def enable_hooks(self):\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name in self.explainable_module_names:  # Skip the explainable_node by its name\n",
    "                continue\n",
    "            # Check if the module is a type that we want to hook (Conv2d, Linear, or pooling layers)\n",
    "            if isinstance(module, (torch.nn.Linear, torch.nn.Conv2d, torch.nn.MaxPool2d)):\n",
    "                forward_handle = module.register_forward_hook(self.create_forward_hook(name))\n",
    "                backward_handle = module.register_full_backward_hook(self.create_backward_hook(name))\n",
    "                self.hook_handles.append(forward_handle)\n",
    "                self.hook_handles.append(backward_handle)\n",
    "    def disable_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "        self.hook_handles = []  # Clear the list after removing all hooks\n",
    "\n",
    "    def create_forward_hook(self, layer_name):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.store_activations(layer_name, output)\n",
    "        return forward_hook\n",
    "\n",
    "    def create_backward_hook(self, layer_name):\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.store_gradients(layer_name, grad_output[0])\n",
    "        return backward_hook\n",
    "    def store_activations(self, layer_name, output):\n",
    "        self._store_per_input(self.activations_per_input, layer_name, output)\n",
    "\n",
    "    def store_gradients(self, layer_name, gradient):\n",
    "        # Store gradients for the last epoch\n",
    "        batch_size = gradient.size(0)\n",
    "        for i in range(batch_size):\n",
    "            input_index = self.batch_counter * batch_size + i\n",
    "            if input_index not in self.gradients_per_input:\n",
    "                self.gradients_per_input[input_index] = {}\n",
    "            self.gradients_per_input[input_index][layer_name] = gradient[i].detach().cpu().numpy()\n",
    "    \n",
    "            # Increment the backward batch counter only after processing the first layer (which is the last layer in the forward pass)\n",
    "\n",
    "\n",
    "    def _store_per_input(self, storage_dict, layer_name, tensor):\n",
    "        batch_size = tensor.size(0)\n",
    "        for i in range(batch_size):\n",
    "            input_index = self.batch_counter * batch_size + i\n",
    "            if input_index not in storage_dict:\n",
    "                storage_dict[input_index] = {}\n",
    "            storage_dict[input_index][layer_name] = tensor[i].detach().cpu().numpy()\n",
    "\n",
    "        if layer_name == self.layer_names[-1]:\n",
    "            self.batch_counter += 1\n",
    "\n",
    "    def get_activations(self, input_index):\n",
    "        return self.activations_per_input.get(input_index, None)\n",
    "\n",
    "    def get_gradients(self, input_index):\n",
    "        return self.gradients_per_input.get(input_index, None)\n",
    "\n",
    "    def print_structure(self):\n",
    "        print(\"Explainable Network Structure and Data Summary:\")\n",
    "\n",
    "        # Check if there is any data collected\n",
    "        if not self.activations_per_input:\n",
    "            print(\"No activations data collected.\")\n",
    "            return\n",
    "\n",
    "        if not self.gradients_per_input:\n",
    "            print(\"No gradients data collected.\")\n",
    "            return\n",
    "\n",
    "        # Print information about activations\n",
    "        print(\"\\nActivations:\")\n",
    "        first_input_activations = next(iter(self.activations_per_input.values()))\n",
    "        for layer_name, activations in first_input_activations.items():\n",
    "            num_nodes = len(activations)\n",
    "            num_data_points = len(self.activations_per_input)\n",
    "            print(f\"Layer {layer_name}: {num_nodes} nodes, {num_data_points} data points each\")\n",
    "\n",
    "        # Print information about gradients\n",
    "        print(\"\\nGradients:\")\n",
    "        first_input_gradients = next(iter(self.gradients_per_input.values()))\n",
    "        for layer_name, gradients in first_input_gradients.items():\n",
    "            num_nodes = len(gradients)\n",
    "            num_data_points = len(self.gradients_per_input)\n",
    "            print(f\"Layer {layer_name}: {num_nodes} nodes, {num_data_points} data points each\")\n",
    "            \n",
    "    # FIXME: Add functionality for first layer\n",
    "    def get_node_input(self, layer_name, node_index, image_index):\n",
    "        if layer_name != self.layer_names[0] and layer_name in self.layer_names:\n",
    "            # For subsequent layers, we use activations from the previous layer\n",
    "            prev_layer_name = self.get_previous_layer_name(layer_name)\n",
    "            prev_activations = self.activations_per_input[image_index][prev_layer_name]\n",
    "        \n",
    "            # Ensure the prev_activations is a 1D array for proper multiplication\n",
    "            if prev_activations.ndim > 1:\n",
    "                prev_activations = prev_activations.flatten()\n",
    "\n",
    "        return prev_activations\n",
    "\n",
    "    def find_extreme_activations(self, std_dev_threshold=3, label_digit=0, pred_digit=0):\n",
    "            \"\"\"\n",
    "            Find inputs where node activations are more than +3 or less than -3 standard deviations from the mean.\n",
    "\n",
    "            Args:\n",
    "            std_dev_threshold (float): The number of standard deviations to use as a threshold for extreme activations.\n",
    "\n",
    "            Returns:\n",
    "            dict: A dictionary containing two keys ('high' and 'low') each mapping to a dict of nodes and their corresponding extreme input indices.\n",
    "            \"\"\"\n",
    "\n",
    "            # Calculate mean and standard deviation for each node\n",
    "            node_stats = {}  # Dictionary to store mean and std for each node\n",
    "            for _, layers_activations in self.activations_per_input.items():\n",
    "                for layer_name, activations in layers_activations.items():\n",
    "                    if layer_name not in node_stats:\n",
    "                        node_stats[layer_name] = []\n",
    "                    node_stats[layer_name].append(activations)\n",
    "\n",
    "            for layer_name, activations_list in node_stats.items():\n",
    "                node_stats[layer_name] = {\n",
    "                    'mean': np.mean(activations_list, axis=0),\n",
    "                    'std': np.std(activations_list, axis=0)\n",
    "                }\n",
    "\n",
    "            activations_structure = {}\n",
    "\n",
    "            # Assuming 'model' is your neural network model\n",
    "            for name, module in self.model.named_modules():\n",
    "                # Skip the model itself as it's also returned by named_modules\n",
    "                if name != \"\" and name in self.layer_names:\n",
    "                    activations_structure[name] = {'high': {}, 'low': {}}\n",
    "\n",
    "            # Identify inputs with extreme activations\n",
    "            for input_index, layers_activations in self.activations_per_input.items():\n",
    "                for layer_name, activations in layers_activations.items():\n",
    "                    if self.expected_outputs[input_index] == label_digit and self.predicted_outputs[input_index] == pred_digit:\n",
    "                        mean = node_stats[layer_name]['mean']\n",
    "                        std = node_stats[layer_name]['std']\n",
    "                        high_threshold = mean + std_dev_threshold * std\n",
    "                        low_threshold = mean - std_dev_threshold * std\n",
    "\n",
    "                        high_indices = np.where(activations > high_threshold)[0]\n",
    "                        low_indices = np.where(activations < low_threshold)[0]\n",
    "\n",
    "                        for idx in high_indices:\n",
    "                            activations_structure[layer_name]['high'][idx] = activations_structure[layer_name]['high'].get(idx, 0) + 1\n",
    "                        for idx in low_indices:\n",
    "                            activations_structure[layer_name]['low'][idx] = activations_structure[layer_name]['low'].get(idx, 0) + 1\n",
    "            return activations_structure\n",
    "            \n",
    "    def get_previous_layer_name(self, current_layer_name):\n",
    "        try:\n",
    "            index = self.layer_names.index(current_layer_name)\n",
    "        except ValueError:\n",
    "            print(\"Layer name not found in the model.\")\n",
    "            return None\n",
    "        \n",
    "        if index == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return self.layer_names[index - 1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6a464a-132e-4e38-a4e9-0fa008769010",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainable_net = ExplainableNetwork(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d198f0e3-bf5f-43a8-98c6-1c3cedd57c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()  # Set the network to training mode\n",
    "\n",
    "for images, labels in trainloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Zero the parameter gradients\n",
    "    net.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = net(images)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass to compute gradients\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c9cda3e-da41-445c-8a95-01aeae54a6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainable Network Structure and Data Summary:\n",
      "\n",
      "Activations:\n",
      "Layer conv1: 32 nodes, 60000 data points each\n",
      "Layer pool: 64 nodes, 60000 data points each\n",
      "Layer conv2: 64 nodes, 60000 data points each\n",
      "Layer fc1: 128 nodes, 60000 data points each\n",
      "Layer fc2: 64 nodes, 60000 data points each\n",
      "Layer fc3: 10 nodes, 60000 data points each\n",
      "\n",
      "Gradients:\n",
      "Layer fc3: 10 nodes, 60000 data points each\n",
      "Layer fc2: 64 nodes, 60000 data points each\n",
      "Layer fc1: 128 nodes, 60000 data points each\n",
      "Layer pool: 32 nodes, 60000 data points each\n",
      "Layer conv2: 64 nodes, 60000 data points each\n",
      "Layer conv1: 32 nodes, 60000 data points each\n"
     ]
    }
   ],
   "source": [
    "explainable_net.print_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "250067aa-9c84-4f6e-bcb4-97b679e96186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Output: tensor([[-16.6261,  -7.4099,  -7.6156,  22.6847, -11.1909,   2.0315, -12.6433,\n",
      "          -1.7090,   1.4503,  -6.2504]], device='cuda:0')\n",
      "Explainable Output: tensor(1.2106, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs = all_images[12].unsqueeze(0).to(device)  # Add a batch dimension\n",
    "\n",
    "net.eval()\n",
    "\n",
    "# Forward pass to get both outputs\n",
    "with torch.no_grad():\n",
    "    regular_output, explainable_output = net(inputs, return_explainable=True)\n",
    "\n",
    "print(\"Regular Output:\", regular_output)\n",
    "print(\"Explainable Output:\", explainable_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75066ade-cbf8-4edb-b3d9-eca1841d1a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d297c4-0fd3-4086-9e20-2941a801cf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
