{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3ad227f-3b99-4b27-8dde-488a8f09d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbede7a4-b225-4375-adde-a654d0b0c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Set the seed for reproducibility.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  # Set the seed for numpy for reproducibility\n",
    "    random.seed(seed)  # Set Python random seed\n",
    "    # Ensures that CUDA operations are deterministic\n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Example: Setting the seed to 42\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be405b7c-7856-43d6-b8a0-e67f71d67089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "batch_size = 32\n",
    "# Transform to convert images to PyTorch tensors and normalize them\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data for MNIST\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c52e048-50b2-469a-a2fa-d4c55e423e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZgUlEQVR4nO3df2zU953n8ddgYGLQMCuX2DNTHK+Vg2uFEd0CBXz8MGywmFVQiBMtSXQ9I7UoaQwn5ETZUnaFryvhLBUs0rqhapqloEJBJxGCBBviHNgUEboOIhsvTZGzmOAsnrr4Eo8xZBzgc3/4mN3BBvI1M3577OdD+krxzPfDvPPtV33yzcx87XPOOQEAYGCM9QAAgNGLCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNjrQe4061bt3T58mUFAgH5fD7rcQAAHjnn1N3drUgkojFj7n2tM+widPnyZRUWFlqPAQB4QG1tbZoyZco99xl2EQoEApKkBfoLjdU442kAAF7d0Jc6qSPJ/z+/l4xF6LXXXtNPfvITtbe3a/r06dq+fbsWLlx433W3/xPcWI3TWB8RAoCs8//vSPpV3lLJyAcT9u/fr/Xr12vjxo06e/asFi5cqGg0qkuXLmXi5QAAWSojEdq2bZu+973v6fvf/76++c1vavv27SosLNSOHTsy8XIAgCyV9gj19vbqzJkzKi8vT3m8vLxcp06d6rd/IpFQPB5P2QAAo0PaI3TlyhXdvHlTBQUFKY8XFBQoFov127+2tlbBYDC58ck4ABg9MvZl1TvfkHLODfgm1YYNG9TV1ZXc2traMjUSAGCYSfun4yZPnqycnJx+Vz0dHR39ro4kye/3y+/3p3sMAEAWSPuV0Pjx4zVr1izV19enPF5fX6/S0tJ0vxwAIItl5HtC1dXV+u53v6vZs2dr/vz5+vnPf65Lly7phRdeyMTLAQCyVEYitGrVKnV2durHP/6x2tvbVVJSoiNHjqioqCgTLwcAyFI+55yzHuI/i8fjCgaDKtMT3DEBALLQDfelGvSWurq6NGnSpHvuy69yAACYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMyMtR4AALzoeXqu5zV/t2XHoF7rb//yf3he497/10G91mjFlRAAwAwRAgCYSXuEampq5PP5UrZQKJTulwEAjAAZeU9o+vTpevfdd5M/5+TkZOJlAABZLiMRGjt2LFc/AID7ysh7Qi0tLYpEIiouLtYzzzyjCxcu3HXfRCKheDyesgEARoe0R2ju3LnavXu3jh49qtdff12xWEylpaXq7OwccP/a2loFg8HkVlhYmO6RAADDVNojFI1G9dRTT2nGjBl67LHHdPjwYUnSrl27Btx/w4YN6urqSm5tbW3pHgkAMExl/MuqEydO1IwZM9TS0jLg836/X36/P9NjAACGoYx/TyiRSOijjz5SOBzO9EsBALJM2iP08ssvq7GxUa2trfrtb3+rp59+WvF4XJWVlel+KQBAlkv7f4779NNP9eyzz+rKlSt6+OGHNW/ePJ0+fVpFRUXpfikAQJZLe4T27duX7j9yRLj+xHe8r/ma9y/55v3je57XANmkY7b3/4DztxdXZGASpAP3jgMAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzGT8l9qhz+VF3ns/4dHPvb/QP3pfApgZ4/0mve6R657X/Hn+7z2vkaT/4ysd1Dp8dVwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAx30R4i/+vx/+15zd99VJ6BSYDhI+fRIs9rfr/Y+63iv/XP/93zGkmKNDUPah2+Oq6EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAz3MB0iIzz3bAeARh2xv7i2pC8zvV/mzQkrwPvuBICAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMxwA9NBuLXgW57XLHzoZPoHAbLcn07sHJLXKXz35pC8DrzjSggAYIYIAQDMeI7QiRMntGLFCkUiEfl8Ph08eDDleeecampqFIlElJubq7KyMp07dy5d8wIARhDPEerp6dHMmTNVV1c34PNbtmzRtm3bVFdXp6amJoVCIS1btkzd3d0PPCwAYGTx/MGEaDSqaDQ64HPOOW3fvl0bN25URUWFJGnXrl0qKCjQ3r179fzzzz/YtACAESWt7wm1trYqFoupvLw8+Zjf79fixYt16tSpAdckEgnF4/GUDQAwOqQ1QrFYTJJUUFCQ8nhBQUHyuTvV1tYqGAwmt8LCwnSOBAAYxjLy6Tifz5fys3Ou32O3bdiwQV1dXcmtra0tEyMBAIahtH5ZNRQKSeq7IgqHw8nHOzo6+l0d3eb3++X3+9M5BgAgS6T1Sqi4uFihUEj19fXJx3p7e9XY2KjS0tJ0vhQAYATwfCV09epVffzxx8mfW1tb9cEHHygvL0+PPPKI1q9fr82bN2vq1KmaOnWqNm/erAkTJui5555L6+AAgOznOULvv/++lixZkvy5urpaklRZWalf/vKXeuWVV3T9+nW9+OKL+uyzzzR37ly98847CgQC6ZsaADAieI5QWVmZnHN3fd7n86mmpkY1NTUPMtew9snjuZ7X5OdMyMAkwPAx9k8f8bzm6bxDGZikv9zWzwa1jtueZh73jgMAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZtP5m1dFi7H/pHpLX+eL3fzIkrwOkQ9v2iZ7X/Df/Lc9r3ohP8bxGn8e9r8GQ4EoIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADDDDUyHsfz3vd/cESNXzuSveV7zh6emDeq18v7yU89rGqe9MYhXesjzih0/Xel5Tf4fTnleg6HBlRAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYbmA5j1/O8/x1hYgbmSKdbC//M8xqX4/O8pu0xv+c1ktQb+dLzmjHjb3pe887Cf/C8Zpz3w6DYzcEdh7+58KTnNf/3lvcb7k4Y4/3YFfy22/Ma53kFhgpXQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGW5gOgiJL8Z5XnNrELdQ3Pmjv/e85tDab3leM5T+6mu/8LxmjLzfufO66/W8RpIu3/R+Q826P5Z5XvPYu+s9r/mTs+M9rwm/8wfPayTJ98mnntf88aNcz2sKcrzfMNY1NXteg+GLKyEAgBkiBAAw4zlCJ06c0IoVKxSJROTz+XTw4MGU51evXi2fz5eyzZs3L13zAgBGEM8R6unp0cyZM1VXV3fXfZYvX6729vbkduTIkQcaEgAwMnn+YEI0GlU0Gr3nPn6/X6FQaNBDAQBGh4y8J9TQ0KD8/HxNmzZNa9asUUdHx133TSQSisfjKRsAYHRIe4Si0aj27NmjY8eOaevWrWpqatLSpUuVSCQG3L+2tlbBYDC5FRYWpnskAMAwlfbvCa1atSr5zyUlJZo9e7aKiop0+PBhVVRU9Nt/w4YNqq6uTv4cj8cJEQCMEhn/smo4HFZRUZFaWloGfN7v98vv92d6DADAMJTx7wl1dnaqra1N4XA40y8FAMgynq+Erl69qo8//jj5c2trqz744APl5eUpLy9PNTU1euqppxQOh3Xx4kX96Ec/0uTJk/Xkk0+mdXAAQPbzHKH3339fS5YsSf58+/2cyspK7dixQ83Nzdq9e7c+//xzhcNhLVmyRPv371cgEEjf1ACAEcHnnPN+Z80MisfjCgaDKtMTGuvzfqPQ4aq1dr7nNYVz/j0Dk2SfP/7TFM9rvnbO+40xJWn8202DWjfS/PtflXpe8y//8+5fYL+bfVcf9rxm93/lg0vD3Q33pRr0lrq6ujRp0qR77su94wAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGAm479ZFX2KN7xnPULWCuuS9QijzoRFfxyS1/nr4095XjNN/5yBSWCFKyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAw3MAVgpugtZz0CjHElBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwM9Z6AAAjQ47P+99pP5s2zvOa0D95XoJhjCshAIAZIgQAMOMpQrW1tZozZ44CgYDy8/O1cuVKnT9/PmUf55xqamoUiUSUm5ursrIynTt3Lq1DAwBGBk8RamxsVFVVlU6fPq36+nrduHFD5eXl6unpSe6zZcsWbdu2TXV1dWpqalIoFNKyZcvU3d2d9uEBANnN0wcT3n777ZSfd+7cqfz8fJ05c0aLFi2Sc07bt2/Xxo0bVVFRIUnatWuXCgoKtHfvXj3//PPpmxwAkPUe6D2hrq4uSVJeXp4kqbW1VbFYTOXl5cl9/H6/Fi9erFOnTg34ZyQSCcXj8ZQNADA6DDpCzjlVV1drwYIFKikpkSTFYjFJUkFBQcq+BQUFyefuVFtbq2AwmNwKCwsHOxIAIMsMOkJr167Vhx9+qF//+tf9nvP5fCk/O+f6PXbbhg0b1NXVldza2toGOxIAIMsM6suq69at06FDh3TixAlNmTIl+XgoFJLUd0UUDoeTj3d0dPS7OrrN7/fL7/cPZgwAQJbzdCXknNPatWt14MABHTt2TMXFxSnPFxcXKxQKqb6+PvlYb2+vGhsbVVpamp6JAQAjhqcroaqqKu3du1dvvfWWAoFA8n2eYDCo3Nxc+Xw+rV+/Xps3b9bUqVM1depUbd68WRMmTNBzzz2XkX8BAED28hShHTt2SJLKyspSHt+5c6dWr14tSXrllVd0/fp1vfjii/rss880d+5cvfPOOwoEAmkZGAAwcniKkHPuvvv4fD7V1NSopqZmsDMByEI33S3vi7hx2KjHKQAAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzg/rNqgCQDtfmXLMeAca4EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHADUwBpkePj77TwjrMGAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADDDDUwB9JN492HPa25+61YGJsFIx5UQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGDG55xz1kP8Z/F4XMFgUGV6QmN946zHAQB4dMN9qQa9pa6uLk2aNOme+3IlBAAwQ4QAAGY8Rai2tlZz5sxRIBBQfn6+Vq5cqfPnz6fss3r1avl8vpRt3rx5aR0aADAyeIpQY2OjqqqqdPr0adXX1+vGjRsqLy9XT09Pyn7Lly9Xe3t7cjty5EhahwYAjAyefrPq22+/nfLzzp07lZ+frzNnzmjRokXJx/1+v0KhUHomBACMWA/0nlBXV5ckKS8vL+XxhoYG5efna9q0aVqzZo06Ojru+mckEgnF4/GUDQAwOgw6Qs45VVdXa8GCBSopKUk+Ho1GtWfPHh07dkxbt25VU1OTli5dqkQiMeCfU1tbq2AwmNwKCwsHOxIAIMsM+ntCVVVVOnz4sE6ePKkpU6bcdb/29nYVFRVp3759qqio6Pd8IpFICVQ8HldhYSHfEwKALOXle0Ke3hO6bd26dTp06JBOnDhxzwBJUjgcVlFRkVpaWgZ83u/3y+/3D2YMAECW8xQh55zWrVunN998Uw0NDSouLr7vms7OTrW1tSkcDg96SADAyOTpPaGqqir96le/0t69exUIBBSLxRSLxXT9+nVJ0tWrV/Xyyy/rvffe08WLF9XQ0KAVK1Zo8uTJevLJJzPyLwAAyF6eroR27NghSSorK0t5fOfOnVq9erVycnLU3Nys3bt36/PPP1c4HNaSJUu0f/9+BQKBtA0NABgZPP/nuHvJzc3V0aNHH2ggAMDowb3jAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmxloPcCfnnCTphr6UnPEwAADPbuhLSf/x/+f3Muwi1N3dLUk6qSPGkwAAHkR3d7eCweA99/G5r5KqIXTr1i1dvnxZgUBAPp8v5bl4PK7CwkK1tbVp0qRJRhPa4zj04Tj04Tj04Tj0GQ7HwTmn7u5uRSIRjRlz73d9ht2V0JgxYzRlypR77jNp0qRRfZLdxnHow3How3How3HoY30c7ncFdBsfTAAAmCFCAAAzWRUhv9+vTZs2ye/3W49iiuPQh+PQh+PQh+PQJ9uOw7D7YAIAYPTIqishAMDIQoQAAGaIEADADBECAJjJqgi99tprKi4u1kMPPaRZs2bpN7/5jfVIQ6qmpkY+ny9lC4VC1mNl3IkTJ7RixQpFIhH5fD4dPHgw5XnnnGpqahSJRJSbm6uysjKdO3fOZtgMut9xWL16db/zY968eTbDZkhtba3mzJmjQCCg/Px8rVy5UufPn0/ZZzScD1/lOGTL+ZA1Edq/f7/Wr1+vjRs36uzZs1q4cKGi0aguXbpkPdqQmj59utrb25Nbc3Oz9UgZ19PTo5kzZ6qurm7A57ds2aJt27aprq5OTU1NCoVCWrZsWfI+hCPF/Y6DJC1fvjzl/DhyZGTdg7GxsVFVVVU6ffq06uvrdePGDZWXl6unpye5z2g4H77KcZCy5HxwWeI73/mOe+GFF1Ie+8Y3vuF++MMfGk009DZt2uRmzpxpPYYpSe7NN99M/nzr1i0XCoXcq6++mnzsiy++cMFg0P3sZz8zmHBo3HkcnHOusrLSPfHEEybzWOno6HCSXGNjo3Nu9J4Pdx4H57LnfMiKK6He3l6dOXNG5eXlKY+Xl5fr1KlTRlPZaGlpUSQSUXFxsZ555hlduHDBeiRTra2tisViKeeG3+/X4sWLR925IUkNDQ3Kz8/XtGnTtGbNGnV0dFiPlFFdXV2SpLy8PEmj93y48zjclg3nQ1ZE6MqVK7p586YKCgpSHi8oKFAsFjOaaujNnTtXu3fv1tGjR/X6668rFouptLRUnZ2d1qOZuf2//2g/NyQpGo1qz549OnbsmLZu3aqmpiYtXbpUiUTCerSMcM6purpaCxYsUElJiaTReT4MdByk7Dkfht1dtO/lzl/t4Jzr99hIFo1Gk/88Y8YMzZ8/X48++qh27dql6upqw8nsjfZzQ5JWrVqV/OeSkhLNnj1bRUVFOnz4sCoqKgwny4y1a9fqww8/1MmTJ/s9N5rOh7sdh2w5H7LiSmjy5MnKycnp9zeZjo6Ofn/jGU0mTpyoGTNmqKWlxXoUM7c/Hci50V84HFZRUdGIPD/WrVunQ4cO6fjx4ym/+mW0nQ93Ow4DGa7nQ1ZEaPz48Zo1a5bq6+tTHq+vr1dpaanRVPYSiYQ++ugjhcNh61HMFBcXKxQKpZwbvb29amxsHNXnhiR1dnaqra1tRJ0fzjmtXbtWBw4c0LFjx1RcXJzy/Gg5H+53HAYybM8Hww9FeLJv3z43btw498Ybb7jf/e53bv369W7ixInu4sWL1qMNmZdeesk1NDS4CxcuuNOnT7vHH3/cBQKBEX8Muru73dmzZ93Zs2edJLdt2zZ39uxZ98knnzjnnHv11VddMBh0Bw4ccM3Nze7ZZ5914XDYxeNx48nT617Hobu727300kvu1KlTrrW11R0/ftzNnz/fff3rXx9Rx+EHP/iBCwaDrqGhwbW3tye3a9euJfcZDefD/Y5DNp0PWRMh55z76U9/6oqKitz48ePdt7/97ZSPI44Gq1atcuFw2I0bN85FIhFXUVHhzp07Zz1Wxh0/ftxJ6rdVVlY65/o+lrtp0yYXCoWc3+93ixYtcs3NzbZDZ8C9jsO1a9dceXm5e/jhh924cePcI4884iorK92lS5esx06rgf79JbmdO3cm9xkN58P9jkM2nQ/8KgcAgJmseE8IADAyESEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABm/h+kZZY8IvAKlQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_images = []\n",
    "all_indices = []\n",
    "\n",
    "for i, (images, labels) in enumerate(trainloader):\n",
    "    all_images.extend(images)\n",
    "    all_indices.extend(range(i * len(images), (i + 1) * len(images)))\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "all_images = torch.stack(all_images)\n",
    "all_indices = torch.tensor(all_indices)\n",
    "\n",
    "\n",
    "\n",
    "# Function to display an image given its index\n",
    "def imshow_by_index(index):\n",
    "    img = all_images[index] / 2 + 0.5  # Unnormalize\n",
    "    plt.imshow(img.permute(1, 2, 0))  # Convert from Tensor image\n",
    "    plt.show()\n",
    "\n",
    "# Example: Display the first four images\n",
    "for i in range(4):\n",
    "    imshow_by_index(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ece47856-c7c8-4aa0-a054-2642278eedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TrainableNode(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(TrainableNode, self).__init__()\n",
    "        self.linear = nn.Linear(input_features, output_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        # Assuming MNIST images are 1x28x28 (channels x width x height)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2) # Output: 32x28x28\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2) # Output: 64x14x14\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # Output: 64x7x7 after pooling\n",
    "        \n",
    "        # Flatten: 64*7*7 = 3136 features\n",
    "        self.fc1 = nn.Linear(3136, 128) # Fully connected layer\n",
    "        \n",
    "        # Trainable node for explainability, assuming it requires a flattened input\n",
    "        self.explainable_node = TrainableNode(128, 1)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64) # Additional fully connected layer\n",
    "        self.fc3 = nn.Linear(64, 10) # Final layer for classifying into 10 classes\n",
    "        \n",
    "    def forward(self, x, return_explainable=False):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x1 = F.relu(self.fc1(x))\n",
    "        \n",
    "        if return_explainable:\n",
    "            explainable_output = self.explainable_node(x1).squeeze()\n",
    "        \n",
    "        x = F.relu(self.fc2(x1))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        if return_explainable:\n",
    "            return x, explainable_output\n",
    "        return x\n",
    "\n",
    "class ExplainableNetwork:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.activations_per_input = {}\n",
    "        self.weights_per_layer = {}\n",
    "        self.gradients_per_input = {} \n",
    "        self.current_epoch = 0\n",
    "        self.num_epochs = 0\n",
    "        self.batch_counter = 0\n",
    "\n",
    "        self.expected_outputs = []\n",
    "        self.predicted_outputs = []\n",
    "        \n",
    "        # Register hooks for each layer\n",
    "        for name, module in model.named_modules():\n",
    "            if name == 'explainable_node':  # Skip the explainable_node by its name\n",
    "                continue\n",
    "            if isinstance(module, torch.nn.Linear) or isinstance(module, torch.nn.Conv2d):  # Include Conv1d here\n",
    "                self.weights_per_layer[name] = None\n",
    "                module.register_forward_hook(self.create_forward_hook(name))\n",
    "                module.register_full_backward_hook(self.create_backward_hook(name))\n",
    "\n",
    "\n",
    "    def create_forward_hook(self, layer_name):\n",
    "        def forward_hook(module, input, output):\n",
    "            # On the last epoch, store activations for each input\n",
    "            if self.current_epoch == self.num_epochs - 1:\n",
    "                self.store_activations(layer_name, output)\n",
    "            # Always store the current weights\n",
    "            self.weights_per_layer[layer_name] = module.weight.data.clone()\n",
    "        return forward_hook\n",
    "\n",
    "    def create_backward_hook(self, layer_name):\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            # Only store gradients on the last epoch\n",
    "            if self.current_epoch == self.num_epochs - 1:\n",
    "                # grad_output[0] contains the gradient with respect to the output of the layer\n",
    "                self.store_gradients(layer_name, grad_output[0])\n",
    "        return backward_hook\n",
    "\n",
    "\n",
    "    def store_activations(self, layer_name, output):\n",
    "        self._store_per_input(self.activations_per_input, layer_name, output)\n",
    "\n",
    "    def store_gradients(self, layer_name, gradient):\n",
    "        # Store gradients for the last epoch\n",
    "        if self.current_epoch == self.num_epochs - 1:\n",
    "            batch_size = gradient.size(0)\n",
    "            for i in range(batch_size):\n",
    "                input_index = self.batch_counter * batch_size + i\n",
    "                if input_index not in self.gradients_per_input:\n",
    "                    self.gradients_per_input[input_index] = {}\n",
    "                self.gradients_per_input[input_index][layer_name] = gradient[i].detach().cpu().numpy()\n",
    "    \n",
    "            # Increment the backward batch counter only after processing the first layer (which is the last layer in the forward pass)\n",
    "\n",
    "\n",
    "    def _store_per_input(self, storage_dict, layer_name, tensor):\n",
    "        batch_size = tensor.size(0)\n",
    "        for i in range(batch_size):\n",
    "            input_index = self.batch_counter * batch_size + i\n",
    "            if input_index not in storage_dict:\n",
    "                storage_dict[input_index] = {}\n",
    "            storage_dict[input_index][layer_name] = tensor[i].detach().cpu().numpy()\n",
    "\n",
    "        if layer_name == list(self.model.named_modules())[-1][0]:\n",
    "            self.batch_counter += 1\n",
    "\n",
    "    def start_epoch(self, epoch, num_epochs):\n",
    "        self.current_epoch = epoch\n",
    "        self.num_epochs = num_epochs\n",
    "        if epoch == num_epochs - 1:\n",
    "            self.batch_counter = 0  # Reset the batch counter on the last epoch\n",
    "\n",
    "    def get_activations(self, input_index):\n",
    "        return self.activations_per_input.get(input_index, None)\n",
    "\n",
    "    def get_gradients(self, input_index):\n",
    "        return self.gradients_per_input.get(input_index, None)\n",
    "\n",
    "    def print_structure(self):\n",
    "        print(\"Explainable Network Structure and Data Summary:\")\n",
    "\n",
    "        # Check if there is any data collected\n",
    "        if not self.activations_per_input:\n",
    "            print(\"No activations data collected.\")\n",
    "            return\n",
    "\n",
    "        if not self.gradients_per_input:\n",
    "            print(\"No gradients data collected.\")\n",
    "            return\n",
    "\n",
    "        # Print information about activations\n",
    "        print(\"\\nActivations:\")\n",
    "        first_input_activations = next(iter(self.activations_per_input.values()))\n",
    "        for layer_name, activations in first_input_activations.items():\n",
    "            num_nodes = len(activations)\n",
    "            num_data_points = len(self.activations_per_input)\n",
    "            print(f\"Layer {layer_name}: {num_nodes} nodes, {num_data_points} data points each\")\n",
    "\n",
    "        # Print information about gradients\n",
    "        print(\"\\nGradients:\")\n",
    "        first_input_gradients = next(iter(self.gradients_per_input.values()))\n",
    "        for layer_name, gradients in first_input_gradients.items():\n",
    "            num_nodes = len(gradients)\n",
    "            num_data_points = len(self.gradients_per_input)\n",
    "            print(f\"Layer {layer_name}: {num_nodes} nodes, {num_data_points} data points each\")\n",
    "\n",
    "    def get_node_input(self, layer_name, node_index, image_index):\n",
    "\n",
    "        if layer_name == 'fc1':\n",
    "            # For the first layer, the input is the raw image data\n",
    "            # Assuming you have a way to access the raw input images\n",
    "            pass\n",
    "        else:\n",
    "            # For subsequent layers, we use activations from the previous layer\n",
    "            prev_layer_name = self.get_previous_layer_name(layer_name)\n",
    "            prev_activations = self.activations_per_input[image_index][prev_layer_name]\n",
    "\n",
    "            # Ensure the prev_activations is a 1D array for proper multiplication\n",
    "            if prev_activations.ndim > 1:\n",
    "                prev_activations = prev_activations.flatten()\n",
    "\n",
    "        return prev_activations\n",
    "            \n",
    "    def get_previous_layer_name(self, current_layer_name):\n",
    "        # Correctly compare current_layer_name with expected values\n",
    "        if current_layer_name == 'fc3':\n",
    "            return 'fc2'\n",
    "        elif current_layer_name == 'fc2':\n",
    "            return 'fc1'\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad3191bc-1113-4415-9a9e-10197b7cb65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Instantiate the model and move it to the GPU if available\n",
    "model = MNISTNet().to(device)\n",
    "\n",
    "# Set the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the optimizer (e.g., Adam or SGD)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d12179ff-b943-48b8-890f-444960d9273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTNet().to(device)\n",
    "explainable_net = ExplainableNetwork(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10  # Adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    explainable_net.start_epoch(epoch, num_epochs)\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        if epoch == num_epochs - 1:\n",
    "            explainable_net.expected_outputs.extend(targets.cpu().numpy())\n",
    "            \n",
    "            # Convert outputs to predicted class labels\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            explainable_net.predicted_outputs.extend(predicted.cpu().numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6470a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainable Network Structure and Data Summary:\n",
      "\n",
      "Activations:\n",
      "Layer conv1: 32 nodes, 60000 data points each\n",
      "Layer conv2: 64 nodes, 60000 data points each\n",
      "Layer fc1: 128 nodes, 60000 data points each\n",
      "Layer fc2: 64 nodes, 60000 data points each\n",
      "Layer fc3: 10 nodes, 60000 data points each\n",
      "\n",
      "Gradients:\n",
      "Layer fc3: 10 nodes, 60000 data points each\n",
      "Layer fc2: 64 nodes, 60000 data points each\n",
      "Layer fc1: 128 nodes, 60000 data points each\n",
      "Layer conv2: 64 nodes, 60000 data points each\n",
      "Layer conv1: 32 nodes, 60000 data points each\n"
     ]
    }
   ],
   "source": [
    "explainable_net.print_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22edfbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "60000\n",
      "Sample of Expected Outputs: [5, 0, 4, 1, 9, 2, 1, 3, 1, 4]\n",
      "Sample of Predicted Outputs: [5, 0, 4, 1, 9, 2, 1, 3, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "sample_size = 10\n",
    "\n",
    "print(len(explainable_net.expected_outputs))\n",
    "print(len(explainable_net.predicted_outputs))\n",
    "\n",
    "print(\"Sample of Expected Outputs:\", explainable_net.expected_outputs[:sample_size])\n",
    "print(\"Sample of Predicted Outputs:\", explainable_net.predicted_outputs[:sample_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cc9265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_for_extreme_outliers(explainable_network, layer_name, node_index, std_dev_threshold=3):\n",
    "    activations = []\n",
    "    gradients = []\n",
    "    colors = []\n",
    "\n",
    "    # Define a color map for digits 0-9\n",
    "    color_map = matplotlib.colormaps['tab10']\n",
    "\n",
    "    # Retrieve activations, gradients, and check for correct predictions\n",
    "    for input_index, (expected, predicted) in enumerate(zip(explainable_network.expected_outputs, explainable_network.predicted_outputs)):\n",
    "        if expected == predicted:\n",
    "            activation = explainable_network.get_activations(input_index)\n",
    "            gradient = explainable_network.get_gradients(input_index)\n",
    "\n",
    "            if activation is not None and gradient is not None:\n",
    "                activations.append(activation[layer_name][node_index])\n",
    "                gradients.append(-gradient[layer_name][node_index])  # Negative of the gradient\n",
    "                colors.append(color_map(expected))  # Color code based on the correct digit\n",
    "\n",
    "    # Convert lists to numpy arrays for numerical operations\n",
    "    activations = np.array(activations)\n",
    "    gradients = np.array(gradients)\n",
    "    colors = np.array(colors)\n",
    "\n",
    "    # Calculate mean and standard deviation for activations and gradients\n",
    "    activation_mean = np.mean(activations)\n",
    "    activation_std = np.std(activations)\n",
    "    gradient_mean = np.mean(gradients)\n",
    "    gradient_std = np.std(gradients)\n",
    "\n",
    "    # Apply filtering for points that are more than std_dev_threshold away in both dimensions\n",
    "    extreme_outliers = (np.abs(activations - activation_mean) > std_dev_threshold * activation_std) & \\\n",
    "                       (np.abs(gradients - gradient_mean) > std_dev_threshold * gradient_std)\n",
    "\n",
    "    # Filter activations, gradients, and colors based on the extreme outlier condition\n",
    "    activations_extreme = activations[extreme_outliers]\n",
    "    gradients_extreme = gradients[extreme_outliers]\n",
    "    colors_extreme = colors[extreme_outliers]\n",
    "\n",
    "    # Generate scatter plot with extreme outliers\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    scatter = ax.scatter(activations_extreme, gradients_extreme, c=colors_extreme, cmap=color_map, s=15)\n",
    "    ax.set_xlabel('Activation')\n",
    "    ax.set_ylabel('Negative of Gradient')\n",
    "    ax.set_title(f'Extreme Outliers Scatter Plot for {layer_name} - Node {node_index}')\n",
    "\n",
    "    # Create a colorbar\n",
    "    cbar = plt.colorbar(matplotlib.cm.ScalarMappable(cmap=color_map, norm=plt.Normalize(0, 9)), ax=ax, ticks=np.arange(0, 10))\n",
    "    cbar.set_label('Digit')\n",
    "\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "#plot_scatter_for_extreme_outliers(explainable_net, 'fc2', 3, std_dev_threshold=1.5)  # Adjust std_dev_threshold as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "293ee0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizes the predictions (i, j) to the total number of predictions(i, _) for all predictions\n",
    "# Returns a 2D array such that probabilities[i][j] holds the probability of the model\n",
    "# predicting last_layer[i] as last_layer[j]\n",
    "def calculate_probabilities(classifier_outcomes, label_counts):\n",
    "    probabilities = np.zeros_like(classifier_outcomes, dtype=np.float64)\n",
    "    for i in range(len(label_counts)):\n",
    "        if label_counts[i] > 0:  # Prevent division by zero\n",
    "            probabilities[i] = classifier_outcomes[i] / label_counts[i]\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77798c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 99.13%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "final_layer_size = list(explainable_net.model.named_modules())[-1][1].out_features\n",
    "# classifier_outcomes[i][j] will store the probability of the model incorrectly classifying digit i as digit j.\n",
    "# The diagonals store the probability of a correct predicition\n",
    "classifier_outcomes = np.zeros((final_layer_size, final_layer_size), dtype=np.float64)\n",
    "label_counts = np.zeros(final_layer_size, dtype=np.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Initialize classifier_outcomes as the frequency of each prediction (label, pred)\n",
    "        for label, pred in zip(labels, predicted):\n",
    "            classifier_outcomes[label.item()][pred.item()] += 1\n",
    "            # Store the number of total attempts at predicting 'label'\n",
    "            label_counts[label.item()] += 1\n",
    "\n",
    "classifier_outcomes = calculate_probabilities(classifier_outcomes, label_counts)\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the 10000 test images: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aba9889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Predicted 0  Predicted 1  Predicted 2  Predicted 3  Predicted 4  \\\n",
      "Actual 0       0.9969       0.0000       0.0010       0.0000       0.0000   \n",
      "Actual 1       0.0000       0.9938       0.0026       0.0000       0.0009   \n",
      "Actual 2       0.0000       0.0000       0.9990       0.0000       0.0000   \n",
      "Actual 3       0.0000       0.0000       0.0030       0.9911       0.0000   \n",
      "Actual 4       0.0000       0.0000       0.0000       0.0000       0.9868   \n",
      "Actual 5       0.0011       0.0000       0.0000       0.0022       0.0000   \n",
      "Actual 6       0.0031       0.0042       0.0000       0.0000       0.0010   \n",
      "Actual 7       0.0000       0.0029       0.0068       0.0000       0.0000   \n",
      "Actual 8       0.0041       0.0000       0.0010       0.0010       0.0000   \n",
      "Actual 9       0.0010       0.0000       0.0000       0.0000       0.0040   \n",
      "\n",
      "          Predicted 5  Predicted 6  Predicted 7  Predicted 8  Predicted 9  \n",
      "Actual 0       0.0000       0.0000       0.0000       0.0010       0.0010  \n",
      "Actual 1       0.0000       0.0018       0.0009       0.0000       0.0000  \n",
      "Actual 2       0.0000       0.0000       0.0010       0.0000       0.0000  \n",
      "Actual 3       0.0030       0.0000       0.0010       0.0010       0.0010  \n",
      "Actual 4       0.0000       0.0041       0.0000       0.0020       0.0071  \n",
      "Actual 5       0.9899       0.0034       0.0011       0.0000       0.0022  \n",
      "Actual 6       0.0042       0.9864       0.0000       0.0010       0.0000  \n",
      "Actual 7       0.0000       0.0000       0.9864       0.0010       0.0029  \n",
      "Actual 8       0.0021       0.0000       0.0000       0.9897       0.0021  \n",
      "Actual 9       0.0010       0.0000       0.0000       0.0020       0.9921  \n"
     ]
    }
   ],
   "source": [
    "# Turns classifier_outcomes into a pandas.DataFrame for easier visualization\n",
    "def display_classifier_outcomes_table(classifier_outcomes, mode='percent'):\n",
    "    size = classifier_outcomes.shape[0]\n",
    "    df = pd.DataFrame(classifier_outcomes, \n",
    "                      columns=[f'Predicted {j}' for j in range(size)], \n",
    "                      index=[f'Actual {i}' for i in range(size)])\n",
    "    \n",
    "    if mode == 'percent':\n",
    "        df = df * 100\n",
    "        fmt = \"{:.4f}%\"\n",
    "    elif mode == 'probability':\n",
    "        fmt = \"{:.4f}\"\n",
    "    \n",
    "    pd.set_option('display.float_format', fmt.format)\n",
    "    \n",
    "    # Display table\n",
    "    print(df)\n",
    "\n",
    "display_classifier_outcomes_table(classifier_outcomes, 'probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7711258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'conv1'\n",
    "node_index = 1\n",
    "std_dev = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd2ba32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81b31fdd-85c4-4799-8812-7c20582d14a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, testloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0487ffe-02eb-4f8e-84b8-4b1039bc9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Batch:   100] loss: 0.913\n",
      "[Epoch: 1, Batch:   200] loss: 0.240\n",
      "[Epoch: 1, Batch:   300] loss: 0.214\n",
      "[Epoch: 1, Batch:   400] loss: 0.136\n",
      "[Epoch: 1, Batch:   500] loss: 0.128\n",
      "[Epoch: 1, Batch:   600] loss: 0.099\n",
      "[Epoch: 1, Batch:   700] loss: 0.086\n",
      "[Epoch: 1, Batch:   800] loss: 0.079\n",
      "[Epoch: 1, Batch:   900] loss: 0.086\n",
      "[Epoch: 1, Batch:  1000] loss: 0.085\n",
      "[Epoch: 1, Batch:  1100] loss: 0.079\n",
      "[Epoch: 1, Batch:  1200] loss: 0.082\n",
      "[Epoch: 1, Batch:  1300] loss: 0.072\n",
      "[Epoch: 1, Batch:  1400] loss: 0.078\n",
      "[Epoch: 1, Batch:  1500] loss: 0.078\n",
      "[Epoch: 1, Batch:  1600] loss: 0.079\n",
      "[Epoch: 1, Batch:  1700] loss: 0.071\n",
      "[Epoch: 1, Batch:  1800] loss: 0.061\n",
      "[Epoch: 2, Batch:   100] loss: 0.066\n",
      "[Epoch: 2, Batch:   200] loss: 0.053\n",
      "[Epoch: 2, Batch:   300] loss: 0.060\n",
      "[Epoch: 2, Batch:   400] loss: 0.046\n",
      "[Epoch: 2, Batch:   500] loss: 0.050\n",
      "[Epoch: 2, Batch:   600] loss: 0.047\n",
      "[Epoch: 2, Batch:   700] loss: 0.037\n",
      "[Epoch: 2, Batch:   800] loss: 0.036\n",
      "[Epoch: 2, Batch:   900] loss: 0.055\n",
      "[Epoch: 2, Batch:  1000] loss: 0.034\n",
      "[Epoch: 2, Batch:  1100] loss: 0.047\n",
      "[Epoch: 2, Batch:  1200] loss: 0.043\n",
      "[Epoch: 2, Batch:  1300] loss: 0.053\n",
      "[Epoch: 2, Batch:  1400] loss: 0.047\n",
      "[Epoch: 2, Batch:  1500] loss: 0.037\n",
      "[Epoch: 2, Batch:  1600] loss: 0.045\n",
      "[Epoch: 2, Batch:  1700] loss: 0.048\n",
      "[Epoch: 2, Batch:  1800] loss: 0.029\n",
      "[Epoch: 3, Batch:   100] loss: 0.039\n",
      "[Epoch: 3, Batch:   200] loss: 0.029\n",
      "[Epoch: 3, Batch:   300] loss: 0.037\n",
      "[Epoch: 3, Batch:   400] loss: 0.030\n",
      "[Epoch: 3, Batch:   500] loss: 0.040\n",
      "[Epoch: 3, Batch:   600] loss: 0.031\n",
      "[Epoch: 3, Batch:   700] loss: 0.026\n",
      "[Epoch: 3, Batch:   800] loss: 0.034\n",
      "[Epoch: 3, Batch:   900] loss: 0.038\n",
      "[Epoch: 3, Batch:  1000] loss: 0.021\n",
      "[Epoch: 3, Batch:  1100] loss: 0.030\n",
      "[Epoch: 3, Batch:  1200] loss: 0.035\n",
      "[Epoch: 3, Batch:  1300] loss: 0.043\n",
      "[Epoch: 3, Batch:  1400] loss: 0.027\n",
      "[Epoch: 3, Batch:  1500] loss: 0.028\n",
      "[Epoch: 3, Batch:  1600] loss: 0.037\n",
      "[Epoch: 3, Batch:  1700] loss: 0.033\n",
      "[Epoch: 3, Batch:  1800] loss: 0.016\n",
      "[Epoch: 4, Batch:   100] loss: 0.033\n",
      "[Epoch: 4, Batch:   200] loss: 0.024\n",
      "[Epoch: 4, Batch:   300] loss: 0.037\n",
      "[Epoch: 4, Batch:   400] loss: 0.020\n",
      "[Epoch: 4, Batch:   500] loss: 0.010\n",
      "[Epoch: 4, Batch:   600] loss: 0.024\n",
      "[Epoch: 4, Batch:   700] loss: 0.030\n",
      "[Epoch: 4, Batch:   800] loss: 0.024\n",
      "[Epoch: 4, Batch:   900] loss: 0.028\n",
      "[Epoch: 4, Batch:  1000] loss: 0.027\n",
      "[Epoch: 4, Batch:  1100] loss: 0.018\n",
      "[Epoch: 4, Batch:  1200] loss: 0.030\n",
      "[Epoch: 4, Batch:  1300] loss: 0.031\n",
      "[Epoch: 4, Batch:  1400] loss: 0.026\n",
      "[Epoch: 4, Batch:  1500] loss: 0.017\n",
      "[Epoch: 4, Batch:  1600] loss: 0.023\n",
      "[Epoch: 4, Batch:  1700] loss: 0.033\n",
      "[Epoch: 4, Batch:  1800] loss: 0.016\n",
      "[Epoch: 5, Batch:   100] loss: 0.023\n",
      "[Epoch: 5, Batch:   200] loss: 0.018\n",
      "[Epoch: 5, Batch:   300] loss: 0.020\n",
      "[Epoch: 5, Batch:   400] loss: 0.019\n",
      "[Epoch: 5, Batch:   500] loss: 0.022\n",
      "[Epoch: 5, Batch:   600] loss: 0.014\n",
      "[Epoch: 5, Batch:   700] loss: 0.013\n",
      "[Epoch: 5, Batch:   800] loss: 0.020\n",
      "[Epoch: 5, Batch:   900] loss: 0.019\n",
      "[Epoch: 5, Batch:  1000] loss: 0.014\n",
      "[Epoch: 5, Batch:  1100] loss: 0.017\n",
      "[Epoch: 5, Batch:  1200] loss: 0.026\n",
      "[Epoch: 5, Batch:  1300] loss: 0.016\n",
      "[Epoch: 5, Batch:  1400] loss: 0.013\n",
      "[Epoch: 5, Batch:  1500] loss: 0.021\n",
      "[Epoch: 5, Batch:  1600] loss: 0.023\n",
      "[Epoch: 5, Batch:  1700] loss: 0.021\n",
      "[Epoch: 5, Batch:  1800] loss: 0.011\n",
      "[Epoch: 6, Batch:   100] loss: 0.017\n",
      "[Epoch: 6, Batch:   200] loss: 0.017\n",
      "[Epoch: 6, Batch:   300] loss: 0.020\n",
      "[Epoch: 6, Batch:   400] loss: 0.015\n",
      "[Epoch: 6, Batch:   500] loss: 0.009\n",
      "[Epoch: 6, Batch:   600] loss: 0.010\n",
      "[Epoch: 6, Batch:   700] loss: 0.020\n",
      "[Epoch: 6, Batch:   800] loss: 0.019\n",
      "[Epoch: 6, Batch:   900] loss: 0.014\n",
      "[Epoch: 6, Batch:  1000] loss: 0.008\n",
      "[Epoch: 6, Batch:  1100] loss: 0.011\n",
      "[Epoch: 6, Batch:  1200] loss: 0.018\n",
      "[Epoch: 6, Batch:  1300] loss: 0.025\n",
      "[Epoch: 6, Batch:  1400] loss: 0.026\n",
      "[Epoch: 6, Batch:  1500] loss: 0.022\n",
      "[Epoch: 6, Batch:  1600] loss: 0.017\n",
      "[Epoch: 6, Batch:  1700] loss: 0.019\n",
      "[Epoch: 6, Batch:  1800] loss: 0.011\n",
      "[Epoch: 7, Batch:   100] loss: 0.015\n",
      "[Epoch: 7, Batch:   200] loss: 0.017\n",
      "[Epoch: 7, Batch:   300] loss: 0.006\n",
      "[Epoch: 7, Batch:   400] loss: 0.013\n",
      "[Epoch: 7, Batch:   500] loss: 0.010\n",
      "[Epoch: 7, Batch:   600] loss: 0.018\n",
      "[Epoch: 7, Batch:   700] loss: 0.018\n",
      "[Epoch: 7, Batch:   800] loss: 0.012\n",
      "[Epoch: 7, Batch:   900] loss: 0.019\n",
      "[Epoch: 7, Batch:  1000] loss: 0.007\n",
      "[Epoch: 7, Batch:  1100] loss: 0.020\n",
      "[Epoch: 7, Batch:  1200] loss: 0.023\n",
      "[Epoch: 7, Batch:  1300] loss: 0.029\n",
      "[Epoch: 7, Batch:  1400] loss: 0.015\n",
      "[Epoch: 7, Batch:  1500] loss: 0.009\n",
      "[Epoch: 7, Batch:  1600] loss: 0.008\n",
      "[Epoch: 7, Batch:  1700] loss: 0.024\n",
      "[Epoch: 7, Batch:  1800] loss: 0.015\n",
      "[Epoch: 8, Batch:   100] loss: 0.023\n",
      "[Epoch: 8, Batch:   200] loss: 0.009\n",
      "[Epoch: 8, Batch:   300] loss: 0.009\n",
      "[Epoch: 8, Batch:   400] loss: 0.008\n",
      "[Epoch: 8, Batch:   500] loss: 0.015\n",
      "[Epoch: 8, Batch:   600] loss: 0.008\n",
      "[Epoch: 8, Batch:   700] loss: 0.010\n",
      "[Epoch: 8, Batch:   800] loss: 0.008\n",
      "[Epoch: 8, Batch:   900] loss: 0.018\n",
      "[Epoch: 8, Batch:  1000] loss: 0.007\n",
      "[Epoch: 8, Batch:  1100] loss: 0.011\n",
      "[Epoch: 8, Batch:  1200] loss: 0.010\n",
      "[Epoch: 8, Batch:  1300] loss: 0.011\n",
      "[Epoch: 8, Batch:  1400] loss: 0.010\n",
      "[Epoch: 8, Batch:  1500] loss: 0.015\n",
      "[Epoch: 8, Batch:  1600] loss: 0.004\n",
      "[Epoch: 8, Batch:  1700] loss: 0.019\n",
      "[Epoch: 8, Batch:  1800] loss: 0.007\n",
      "[Epoch: 9, Batch:   100] loss: 0.009\n",
      "[Epoch: 9, Batch:   200] loss: 0.017\n",
      "[Epoch: 9, Batch:   300] loss: 0.016\n",
      "[Epoch: 9, Batch:   400] loss: 0.019\n",
      "[Epoch: 9, Batch:   500] loss: 0.006\n",
      "[Epoch: 9, Batch:   600] loss: 0.006\n",
      "[Epoch: 9, Batch:   700] loss: 0.009\n",
      "[Epoch: 9, Batch:   800] loss: 0.009\n",
      "[Epoch: 9, Batch:   900] loss: 0.010\n",
      "[Epoch: 9, Batch:  1000] loss: 0.013\n",
      "[Epoch: 9, Batch:  1100] loss: 0.013\n",
      "[Epoch: 9, Batch:  1200] loss: 0.008\n",
      "[Epoch: 9, Batch:  1300] loss: 0.013\n",
      "[Epoch: 9, Batch:  1400] loss: 0.012\n",
      "[Epoch: 9, Batch:  1500] loss: 0.012\n",
      "[Epoch: 9, Batch:  1600] loss: 0.005\n",
      "[Epoch: 9, Batch:  1700] loss: 0.017\n",
      "[Epoch: 9, Batch:  1800] loss: 0.018\n",
      "[Epoch: 10, Batch:   100] loss: 0.011\n",
      "[Epoch: 10, Batch:   200] loss: 0.010\n",
      "[Epoch: 10, Batch:   300] loss: 0.007\n",
      "[Epoch: 10, Batch:   400] loss: 0.013\n",
      "[Epoch: 10, Batch:   500] loss: 0.008\n",
      "[Epoch: 10, Batch:   600] loss: 0.007\n",
      "[Epoch: 10, Batch:   700] loss: 0.004\n",
      "[Epoch: 10, Batch:   800] loss: 0.008\n",
      "[Epoch: 10, Batch:   900] loss: 0.024\n",
      "[Epoch: 10, Batch:  1000] loss: 0.009\n",
      "[Epoch: 10, Batch:  1100] loss: 0.011\n",
      "[Epoch: 10, Batch:  1200] loss: 0.009\n",
      "[Epoch: 10, Batch:  1300] loss: 0.015\n",
      "[Epoch: 10, Batch:  1400] loss: 0.013\n",
      "[Epoch: 10, Batch:  1500] loss: 0.010\n",
      "[Epoch: 10, Batch:  1600] loss: 0.020\n",
      "[Epoch: 10, Batch:  1700] loss: 0.009\n",
      "[Epoch: 10, Batch:  1800] loss: 0.006\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 99 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_model(model, testloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
